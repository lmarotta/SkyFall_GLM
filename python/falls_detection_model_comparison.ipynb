{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import scipy.io as sio\n",
    "import matlab.engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run matlab script to put data together\n",
    "eng = matlab.engine.connect_matlab()\n",
    "eng.cd(r'C:\\Users\\ishparii\\dev\\SkyFall_GLM', nargout=0)\n",
    "eng.ls(nargout=0)\n",
    "\n",
    "data_CF = eng.TrainingDataSetup([],[],10,0) #location -use all; subjID - use all; n jitter - 10; condition - healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3689, 1215)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.135488</td>\n",
       "      <td>0.023986</td>\n",
       "      <td>-0.222085</td>\n",
       "      <td>-0.034934</td>\n",
       "      <td>0.026296</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>...</td>\n",
       "      <td>1.397463</td>\n",
       "      <td>1.053904</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.570133</td>\n",
       "      <td>0.042151</td>\n",
       "      <td>0.040205</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>0.082633</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>0.142727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.116935</td>\n",
       "      <td>0.041788</td>\n",
       "      <td>-0.259656</td>\n",
       "      <td>-0.036706</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005645</td>\n",
       "      <td>-1.066576</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.592258</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>0.064699</td>\n",
       "      <td>0.077030</td>\n",
       "      <td>0.105936</td>\n",
       "      <td>0.130796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.095297</td>\n",
       "      <td>-0.009186</td>\n",
       "      <td>-0.262737</td>\n",
       "      <td>-0.031153</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>...</td>\n",
       "      <td>1.598681</td>\n",
       "      <td>2.088595</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.766388</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.099145</td>\n",
       "      <td>0.054502</td>\n",
       "      <td>0.070348</td>\n",
       "      <td>0.107281</td>\n",
       "      <td>0.145236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.131588</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.360665</td>\n",
       "      <td>-0.030360</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090903</td>\n",
       "      <td>4.410364</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.510687</td>\n",
       "      <td>0.035452</td>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.043586</td>\n",
       "      <td>0.073470</td>\n",
       "      <td>0.071604</td>\n",
       "      <td>0.098844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.174216</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.339382</td>\n",
       "      <td>-0.049466</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>...</td>\n",
       "      <td>2.029267</td>\n",
       "      <td>4.142067</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.503324</td>\n",
       "      <td>0.045742</td>\n",
       "      <td>0.077608</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.079449</td>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.085266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3         4         5         6         7         8     \\\n",
       "0   1.0   1.0   1.0   3.0 -0.135488  0.023986 -0.222085 -0.034934  0.026296   \n",
       "1   1.0   1.0   1.0   3.0 -0.116935  0.041788 -0.259656 -0.036706  0.028857   \n",
       "2   1.0   1.0   1.0   3.0 -0.095297 -0.009186 -0.262737 -0.031153  0.019380   \n",
       "3   1.0   1.0   1.0   4.0 -0.131588  0.012601  0.360665 -0.030360  0.038864   \n",
       "4   1.0   1.0   1.0   4.0 -0.174216  0.002581  0.339382 -0.049466  0.017201   \n",
       "\n",
       "       9       ...         1205      1206      1207      1208      1209  \\\n",
       "0  0.061168    ...     1.397463  1.053904  1.370951  0.570133  0.042151   \n",
       "1  0.069082    ...     1.005645 -1.066576  1.370951  0.592258  0.044890   \n",
       "2  0.071339    ...     1.598681  2.088595  1.370951  0.766388  0.050949   \n",
       "3  0.070713    ...     2.090903  4.410364  1.370951  0.510687  0.035452   \n",
       "4  0.068173    ...     2.029267  4.142067  1.370951  0.503324  0.045742   \n",
       "\n",
       "       1210      1211      1212      1213      1214  \n",
       "0  0.040205  0.036391  0.082633  0.057698  0.142727  \n",
       "1  0.055954  0.064699  0.077030  0.105936  0.130796  \n",
       "2  0.099145  0.054502  0.070348  0.107281  0.145236  \n",
       "3  0.046974  0.043586  0.073470  0.071604  0.098844  \n",
       "4  0.077608  0.067755  0.079449  0.131446  0.085266  \n",
       "\n",
       "[5 rows x 1215 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_CF_np = np.array(data_CF)\n",
    "data_CF_df = pd.DataFrame(data_CF_np)\n",
    "\n",
    "print(data_CF_df.shape)\n",
    "data_CF_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>location</th>\n",
       "      <th>subj_code</th>\n",
       "      <th>label</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.135488</td>\n",
       "      <td>0.023986</td>\n",
       "      <td>-0.222085</td>\n",
       "      <td>-0.034934</td>\n",
       "      <td>0.026296</td>\n",
       "      <td>0.061168</td>\n",
       "      <td>...</td>\n",
       "      <td>1.397463</td>\n",
       "      <td>1.053904</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.570133</td>\n",
       "      <td>0.042151</td>\n",
       "      <td>0.040205</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>0.082633</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>0.142727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.116935</td>\n",
       "      <td>0.041788</td>\n",
       "      <td>-0.259656</td>\n",
       "      <td>-0.036706</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.005645</td>\n",
       "      <td>-1.066576</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.592258</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>0.064699</td>\n",
       "      <td>0.077030</td>\n",
       "      <td>0.105936</td>\n",
       "      <td>0.130796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.095297</td>\n",
       "      <td>-0.009186</td>\n",
       "      <td>-0.262737</td>\n",
       "      <td>-0.031153</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.071339</td>\n",
       "      <td>...</td>\n",
       "      <td>1.598681</td>\n",
       "      <td>2.088595</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.766388</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.099145</td>\n",
       "      <td>0.054502</td>\n",
       "      <td>0.070348</td>\n",
       "      <td>0.107281</td>\n",
       "      <td>0.145236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.131588</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.360665</td>\n",
       "      <td>-0.030360</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>...</td>\n",
       "      <td>2.090903</td>\n",
       "      <td>4.410364</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.510687</td>\n",
       "      <td>0.035452</td>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.043586</td>\n",
       "      <td>0.073470</td>\n",
       "      <td>0.071604</td>\n",
       "      <td>0.098844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.174216</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.339382</td>\n",
       "      <td>-0.049466</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>...</td>\n",
       "      <td>2.029267</td>\n",
       "      <td>4.142067</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.503324</td>\n",
       "      <td>0.045742</td>\n",
       "      <td>0.077608</td>\n",
       "      <td>0.067755</td>\n",
       "      <td>0.079449</td>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.085266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subj_id  location  subj_code  label         4         5         6  \\\n",
       "0      1.0       1.0        1.0    3.0 -0.135488  0.023986 -0.222085   \n",
       "1      1.0       1.0        1.0    3.0 -0.116935  0.041788 -0.259656   \n",
       "2      1.0       1.0        1.0    3.0 -0.095297 -0.009186 -0.262737   \n",
       "3      1.0       1.0        1.0    4.0 -0.131588  0.012601  0.360665   \n",
       "4      1.0       1.0        1.0    4.0 -0.174216  0.002581  0.339382   \n",
       "\n",
       "          7         8         9    ...         1205      1206      1207  \\\n",
       "0 -0.034934  0.026296  0.061168    ...     1.397463  1.053904  1.370951   \n",
       "1 -0.036706  0.028857  0.069082    ...     1.005645 -1.066576  1.370951   \n",
       "2 -0.031153  0.019380  0.071339    ...     1.598681  2.088595  1.370951   \n",
       "3 -0.030360  0.038864  0.070713    ...     2.090903  4.410364  1.370951   \n",
       "4 -0.049466  0.017201  0.068173    ...     2.029267  4.142067  1.370951   \n",
       "\n",
       "       1208      1209      1210      1211      1212      1213      1214  \n",
       "0  0.570133  0.042151  0.040205  0.036391  0.082633  0.057698  0.142727  \n",
       "1  0.592258  0.044890  0.055954  0.064699  0.077030  0.105936  0.130796  \n",
       "2  0.766388  0.050949  0.099145  0.054502  0.070348  0.107281  0.145236  \n",
       "3  0.510687  0.035452  0.046974  0.043586  0.073470  0.071604  0.098844  \n",
       "4  0.503324  0.045742  0.077608  0.067755  0.079449  0.131446  0.085266  \n",
       "\n",
       "[5 rows x 1215 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "data_CF_df=data_CF_df.rename(columns = {0:'subj_id', 1:'location', 2:'subj_code', 3:'label'})\n",
    "\n",
    "# save data to file\n",
    "data_CF_df.to_csv('data_CF.csv')\n",
    "\n",
    "data_CF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_AF = eng.TrainingDataSetup([],[],10,1) #location -use all; subjID - use all; n jitter - 10; condition - amputees\n",
    "# data_AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2180, 1215)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.316842</td>\n",
       "      <td>-0.513288</td>\n",
       "      <td>-0.181439</td>\n",
       "      <td>-0.012925</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>-0.046057</td>\n",
       "      <td>...</td>\n",
       "      <td>2.123134</td>\n",
       "      <td>4.547600</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>-0.224154</td>\n",
       "      <td>0.387849</td>\n",
       "      <td>0.115181</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>1.697068</td>\n",
       "      <td>0.898328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.455659</td>\n",
       "      <td>-0.570001</td>\n",
       "      <td>-0.196702</td>\n",
       "      <td>-0.015782</td>\n",
       "      <td>-0.160631</td>\n",
       "      <td>-0.045846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235934</td>\n",
       "      <td>0.195153</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.650340</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.086189</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.066306</td>\n",
       "      <td>0.096367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.507856</td>\n",
       "      <td>-0.505835</td>\n",
       "      <td>-0.101515</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.157200</td>\n",
       "      <td>-0.039848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479414</td>\n",
       "      <td>1.480125</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.314882</td>\n",
       "      <td>0.519301</td>\n",
       "      <td>0.181734</td>\n",
       "      <td>0.187125</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>0.098102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.590558</td>\n",
       "      <td>0.190188</td>\n",
       "      <td>-0.231575</td>\n",
       "      <td>-0.013486</td>\n",
       "      <td>-0.147350</td>\n",
       "      <td>-0.051602</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016604</td>\n",
       "      <td>4.085064</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.258867</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>0.077975</td>\n",
       "      <td>0.109353</td>\n",
       "      <td>0.147960</td>\n",
       "      <td>0.176257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.417043</td>\n",
       "      <td>0.047122</td>\n",
       "      <td>-0.179731</td>\n",
       "      <td>-0.011171</td>\n",
       "      <td>-0.153019</td>\n",
       "      <td>-0.044708</td>\n",
       "      <td>...</td>\n",
       "      <td>1.588522</td>\n",
       "      <td>2.037410</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.714722</td>\n",
       "      <td>0.062383</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>0.081353</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>0.216369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3         4         5         6         7         8     \\\n",
       "0   3.0   1.0   0.0   3.0 -0.316842 -0.513288 -0.181439 -0.012925 -0.175567   \n",
       "1   3.0   1.0   0.0   3.0 -0.455659 -0.570001 -0.196702 -0.015782 -0.160631   \n",
       "2   3.0   1.0   0.0   3.0 -0.507856 -0.505835 -0.101515 -0.011607 -0.157200   \n",
       "3   3.0   1.0   0.0   4.0  0.590558  0.190188 -0.231575 -0.013486 -0.147350   \n",
       "4   3.0   1.0   0.0   4.0  0.417043  0.047122 -0.179731 -0.011171 -0.153019   \n",
       "\n",
       "       9       ...         1205      1206      1207      1208      1209  \\\n",
       "0 -0.046057    ...     2.123134  4.547600  1.370951 -0.224154  0.387849   \n",
       "1 -0.045846    ...     1.235934  0.195153  1.370951  0.650340  0.036201   \n",
       "2 -0.039848    ...     1.479414  1.480125  1.370951  0.314882  0.519301   \n",
       "3 -0.051602    ...     2.016604  4.085064  1.370951  0.258867  0.061490   \n",
       "4 -0.044708    ...     1.588522  2.037410  1.370951  0.714722  0.062383   \n",
       "\n",
       "       1210      1211      1212      1213      1214  \n",
       "0  0.115181  0.139960  0.174659  1.697068  0.898328  \n",
       "1  0.086189  0.035767  0.032562  0.066306  0.096367  \n",
       "2  0.181734  0.187125  0.144392  0.205148  0.098102  \n",
       "3  0.056101  0.077975  0.109353  0.147960  0.176257  \n",
       "4  0.068096  0.053171  0.081353  0.036358  0.216369  \n",
       "\n",
       "[5 rows x 1215 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_AF_np = np.array(data_AF)\n",
    "data_AF_df = pd.DataFrame(data_AF_np)\n",
    "\n",
    "print(data_AF_df.shape)\n",
    "data_AF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>location</th>\n",
       "      <th>subj_code</th>\n",
       "      <th>label</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.316842</td>\n",
       "      <td>-0.513288</td>\n",
       "      <td>-0.181439</td>\n",
       "      <td>-0.012925</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>-0.046057</td>\n",
       "      <td>...</td>\n",
       "      <td>2.123134</td>\n",
       "      <td>4.547600</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>-0.224154</td>\n",
       "      <td>0.387849</td>\n",
       "      <td>0.115181</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>1.697068</td>\n",
       "      <td>0.898328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.455659</td>\n",
       "      <td>-0.570001</td>\n",
       "      <td>-0.196702</td>\n",
       "      <td>-0.015782</td>\n",
       "      <td>-0.160631</td>\n",
       "      <td>-0.045846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235934</td>\n",
       "      <td>0.195153</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.650340</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.086189</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.066306</td>\n",
       "      <td>0.096367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.507856</td>\n",
       "      <td>-0.505835</td>\n",
       "      <td>-0.101515</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.157200</td>\n",
       "      <td>-0.039848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479414</td>\n",
       "      <td>1.480125</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.314882</td>\n",
       "      <td>0.519301</td>\n",
       "      <td>0.181734</td>\n",
       "      <td>0.187125</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>0.098102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.590558</td>\n",
       "      <td>0.190188</td>\n",
       "      <td>-0.231575</td>\n",
       "      <td>-0.013486</td>\n",
       "      <td>-0.147350</td>\n",
       "      <td>-0.051602</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016604</td>\n",
       "      <td>4.085064</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.258867</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>0.077975</td>\n",
       "      <td>0.109353</td>\n",
       "      <td>0.147960</td>\n",
       "      <td>0.176257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.417043</td>\n",
       "      <td>0.047122</td>\n",
       "      <td>-0.179731</td>\n",
       "      <td>-0.011171</td>\n",
       "      <td>-0.153019</td>\n",
       "      <td>-0.044708</td>\n",
       "      <td>...</td>\n",
       "      <td>1.588522</td>\n",
       "      <td>2.037410</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.714722</td>\n",
       "      <td>0.062383</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>0.081353</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>0.216369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subj_id  location  subj_code  label         4         5         6  \\\n",
       "0      3.0       1.0        0.0    3.0 -0.316842 -0.513288 -0.181439   \n",
       "1      3.0       1.0        0.0    3.0 -0.455659 -0.570001 -0.196702   \n",
       "2      3.0       1.0        0.0    3.0 -0.507856 -0.505835 -0.101515   \n",
       "3      3.0       1.0        0.0    4.0  0.590558  0.190188 -0.231575   \n",
       "4      3.0       1.0        0.0    4.0  0.417043  0.047122 -0.179731   \n",
       "\n",
       "          7         8         9    ...         1205      1206      1207  \\\n",
       "0 -0.012925 -0.175567 -0.046057    ...     2.123134  4.547600  1.370951   \n",
       "1 -0.015782 -0.160631 -0.045846    ...     1.235934  0.195153  1.370951   \n",
       "2 -0.011607 -0.157200 -0.039848    ...     1.479414  1.480125  1.370951   \n",
       "3 -0.013486 -0.147350 -0.051602    ...     2.016604  4.085064  1.370951   \n",
       "4 -0.011171 -0.153019 -0.044708    ...     1.588522  2.037410  1.370951   \n",
       "\n",
       "       1208      1209      1210      1211      1212      1213      1214  \n",
       "0 -0.224154  0.387849  0.115181  0.139960  0.174659  1.697068  0.898328  \n",
       "1  0.650340  0.036201  0.086189  0.035767  0.032562  0.066306  0.096367  \n",
       "2  0.314882  0.519301  0.181734  0.187125  0.144392  0.205148  0.098102  \n",
       "3  0.258867  0.061490  0.056101  0.077975  0.109353  0.147960  0.176257  \n",
       "4  0.714722  0.062383  0.068096  0.053171  0.081353  0.036358  0.216369  \n",
       "\n",
       "[5 rows x 1215 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "data_AF_df=data_AF_df.rename(columns = {0:'subj_id', 1:'location', 2:'subj_code', 3:'label'})\n",
    "\n",
    "# save data to file\n",
    "data_AF_df.to_csv('data_AF.csv')\n",
    "\n",
    "data_AF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "      <th>location</th>\n",
       "      <th>subj_code</th>\n",
       "      <th>label</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1205</th>\n",
       "      <th>1206</th>\n",
       "      <th>1207</th>\n",
       "      <th>1208</th>\n",
       "      <th>1209</th>\n",
       "      <th>1210</th>\n",
       "      <th>1211</th>\n",
       "      <th>1212</th>\n",
       "      <th>1213</th>\n",
       "      <th>1214</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.316842</td>\n",
       "      <td>-0.513288</td>\n",
       "      <td>-0.181439</td>\n",
       "      <td>-0.012925</td>\n",
       "      <td>-0.175567</td>\n",
       "      <td>-0.046057</td>\n",
       "      <td>...</td>\n",
       "      <td>2.123134</td>\n",
       "      <td>4.547600</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>-0.224154</td>\n",
       "      <td>0.387849</td>\n",
       "      <td>0.115181</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.174659</td>\n",
       "      <td>1.697068</td>\n",
       "      <td>0.898328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.455659</td>\n",
       "      <td>-0.570001</td>\n",
       "      <td>-0.196702</td>\n",
       "      <td>-0.015782</td>\n",
       "      <td>-0.160631</td>\n",
       "      <td>-0.045846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235934</td>\n",
       "      <td>0.195153</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.650340</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.086189</td>\n",
       "      <td>0.035767</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.066306</td>\n",
       "      <td>0.096367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.507856</td>\n",
       "      <td>-0.505835</td>\n",
       "      <td>-0.101515</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.157200</td>\n",
       "      <td>-0.039848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.479414</td>\n",
       "      <td>1.480125</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.314882</td>\n",
       "      <td>0.519301</td>\n",
       "      <td>0.181734</td>\n",
       "      <td>0.187125</td>\n",
       "      <td>0.144392</td>\n",
       "      <td>0.205148</td>\n",
       "      <td>0.098102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.590558</td>\n",
       "      <td>0.190188</td>\n",
       "      <td>-0.231575</td>\n",
       "      <td>-0.013486</td>\n",
       "      <td>-0.147350</td>\n",
       "      <td>-0.051602</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016604</td>\n",
       "      <td>4.085064</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.258867</td>\n",
       "      <td>0.061490</td>\n",
       "      <td>0.056101</td>\n",
       "      <td>0.077975</td>\n",
       "      <td>0.109353</td>\n",
       "      <td>0.147960</td>\n",
       "      <td>0.176257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.417043</td>\n",
       "      <td>0.047122</td>\n",
       "      <td>-0.179731</td>\n",
       "      <td>-0.011171</td>\n",
       "      <td>-0.153019</td>\n",
       "      <td>-0.044708</td>\n",
       "      <td>...</td>\n",
       "      <td>1.588522</td>\n",
       "      <td>2.037410</td>\n",
       "      <td>1.370951</td>\n",
       "      <td>0.714722</td>\n",
       "      <td>0.062383</td>\n",
       "      <td>0.068096</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>0.081353</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>0.216369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subj_id  location  subj_code  label         4         5         6  \\\n",
       "0      3.0       1.0        0.0    3.0 -0.316842 -0.513288 -0.181439   \n",
       "1      3.0       1.0        0.0    3.0 -0.455659 -0.570001 -0.196702   \n",
       "2      3.0       1.0        0.0    3.0 -0.507856 -0.505835 -0.101515   \n",
       "3      3.0       1.0        0.0    4.0  0.590558  0.190188 -0.231575   \n",
       "4      3.0       1.0        0.0    4.0  0.417043  0.047122 -0.179731   \n",
       "\n",
       "          7         8         9    ...         1205      1206      1207  \\\n",
       "0 -0.012925 -0.175567 -0.046057    ...     2.123134  4.547600  1.370951   \n",
       "1 -0.015782 -0.160631 -0.045846    ...     1.235934  0.195153  1.370951   \n",
       "2 -0.011607 -0.157200 -0.039848    ...     1.479414  1.480125  1.370951   \n",
       "3 -0.013486 -0.147350 -0.051602    ...     2.016604  4.085064  1.370951   \n",
       "4 -0.011171 -0.153019 -0.044708    ...     1.588522  2.037410  1.370951   \n",
       "\n",
       "       1208      1209      1210      1211      1212      1213      1214  \n",
       "0 -0.224154  0.387849  0.115181  0.139960  0.174659  1.697068  0.898328  \n",
       "1  0.650340  0.036201  0.086189  0.035767  0.032562  0.066306  0.096367  \n",
       "2  0.314882  0.519301  0.181734  0.187125  0.144392  0.205148  0.098102  \n",
       "3  0.258867  0.061490  0.056101  0.077975  0.109353  0.147960  0.176257  \n",
       "4  0.714722  0.062383  0.068096  0.053171  0.081353  0.036358  0.216369  \n",
       "\n",
       "[5 rows x 1215 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from csv files\n",
    "data_CF_df = pd.read_csv('data_CF.csv', index_col=0)\n",
    "data_CF_df.head()\n",
    "\n",
    "data_AF_df = pd.read_csv('data_AF.csv', index_col=0)\n",
    "data_AF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "Amputee subjects id:  [ 13.  14.  15.  12.  16.  17.  11.]\n",
      "\n",
      "Unique labels:  [ 1.  9.]\n"
     ]
    }
   ],
   "source": [
    "# changing labels: 1 - fall; 9 - non-fall \n",
    "data_CF_df.loc[(data_CF_df.label == 4) | (data_CF_df.label == 3) | (data_CF_df.label == 2), ['label']] = 1\n",
    "data_AF_df.loc[(data_AF_df.label == 4) | (data_AF_df.label == 3) | (data_AF_df.label == 2), ['label']] = 1\n",
    "\n",
    "# change amputee subjects ids\n",
    "max_id_CF = data_CF_df.subj_id.max()\n",
    "print(max_id_CF)\n",
    "data_AF_df.subj_id = data_AF_df.subj_id + max_id_CF\n",
    "print(\"Amputee subjects id: \", data_AF_df.subj_id.unique())\n",
    "print()\n",
    "print(\"Unique labels: \", data_AF_df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1653, 1215)\n",
      "(837, 1215)\n"
     ]
    }
   ],
   "source": [
    "# training and testing data split\n",
    "\n",
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "data_train = data_CF_df.loc[data_CF_df['location'] == 2] # pocket data\n",
    "data_test = data_AF_df.loc[data_AF_df['location'] == 2]\n",
    "\n",
    "#data_train = data_CF_df[(data_CF_df.location == 1) & ((data_CF_df.label>0) & (data_CF_df.label<=4))]\n",
    "#data_test = data_AF_df[(data_AF_df.location == 1) & ((data_AF_df.label>0) & (data_AF_df.label<=4))]\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:  (3837, 1215)\n",
      "\n",
      "All subjects ids:  [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.  15.\n",
      "  16.  17.]\n",
      "Subjects for testing:  [  1.   2.  16.  17.]\n",
      "Subjects for training:  [  3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.  15.]\n",
      "Training data size:  (3056, 1215)\n",
      "Testing data size:  (781, 1215)\n"
     ]
    }
   ],
   "source": [
    "# mix data\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = data_CF_df\n",
    "full_data = data.append(data_AF_df)\n",
    "\n",
    "# location: 0 - N/A; 1 - pouch; 2 - pocket; 3 - hand\n",
    "# subj_code: 0 - amputee; 1 - healthy\n",
    "# label: 1 - slip; 2 - trip; 3 - right; 4 - left\n",
    "full_data = full_data[((full_data.location == 2) | (full_data.location == 3))] # data for pocket + hand\n",
    "print(\"Data size: \", full_data.shape)\n",
    "print()\n",
    "\n",
    "subj_ids = np.sort(np.array(full_data.subj_id.unique()))\n",
    "print(\"All subjects ids: \",subj_ids)\n",
    "\n",
    "# first and last 2 subjects ids for testing\n",
    "test_subjects = subj_ids[np.r_[0:2, -2:0]]\n",
    "print(\"Subjects for testing: \",test_subjects)\n",
    "\n",
    "train_subjects = np.setdiff1d(subj_ids,test_subjects)\n",
    "print(\"Subjects for training: \",train_subjects)\n",
    "\n",
    "data_train = full_data.loc[full_data['subj_id'].isin(train_subjects)]\n",
    "data_test = full_data.loc[full_data['subj_id'].isin(test_subjects)]\n",
    "# group data by subject\n",
    "#groups = full_data.groupby('subj_id')\n",
    "#groups.head()\n",
    "\n",
    "#random.shuffle(groups)\n",
    "\n",
    "#for g, grp in groups:\n",
    "#    print (grp)\n",
    "\n",
    "#data = pd.DataFrame(groups)\n",
    "#print(data.shape)\n",
    "#data.head()\n",
    "\n",
    "#data_train, data_test = train_test_split(data, test_size=0.3)\n",
    "print(\"Training data size: \", data_train.shape)\n",
    "print(\"Testing data size: \",data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training set:  [ 1.  9.]\n",
      "\n",
      "Unique labels in testing set:  [ 1.  9.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in training set: \", data_train.label.unique())\n",
    "print()\n",
    "print(\"Unique labels in testing set: \", data_test.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of features\n",
    "features = list(range(4,1215))\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   4    5    6    7    8    9   10   11   12   13   14   15   16   17   18\n",
      "   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33\n",
      "   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48\n",
      "   49   50   51   52   53   54   55   56   57   58   59   60   61   62   63\n",
      "   64   65   66   67   68   69   70   71   72   73   74   75   76   77   78\n",
      "   79   80   81   82   83   84   85   86   87   88   89   90   91   92   93\n",
      "   94   95   96   97   98   99  175  176  177  178  179  180  181  182  183\n",
      "  184  185  186  187  188  189  190  191  192  193  194  195  196  197  198\n",
      "  199  200  201  202  203  204  205  206  207  208  209  210  211  212  213\n",
      "  214  215  216  217  218  219  220  221  222  223  224  225  226  227  228\n",
      "  229  230  231  232  233  234  235  236  237  238  239  240  241  242  243\n",
      "  244  245  246  247  248  249  250  251  252  253  254  255  256  257  258\n",
      "  259  260  261  262  263  264  340  341  342  343  344  345  346  347  348\n",
      "  349  350  351  352  353  354  355  356  357  358  359  360  361  362  363\n",
      "  364  365  366  367  368  369  370  371  372  373  374  375  376  377  378\n",
      "  379  380  381  382  383  384  385  386  387  388  389  390  391  392  393\n",
      "  394  395  396  397  398  399  400  401  402  403  404  405  406  407  408\n",
      "  409  410  411  412  413  414  415  416  417  418  419  420  421  422  423\n",
      "  424  425  426  427  428  429  430  431  432  433  434  435  436  437  438\n",
      "  439  440  606  607  608  609  610  611  612  613  614  615  616  617  618\n",
      "  619  620  621  622  623  624  625  626  627  628  629  630  631  632  633\n",
      "  634  635  636  637  638  639  640  641  642  643  644  645  646  647  648\n",
      "  649  650  651  652  653  654  655  656  657  658  659  660  661  662  663\n",
      "  664  665  666  667  668  669  670  671  672  673  674  675  676  677  678\n",
      "  679  680  681  682  683  684  685  686  687  688  689  690  691  692  693\n",
      "  694  695  696  697  698  699  700  701  777  778  779  780  781  782  783\n",
      "  784  785  786  787  788  789  790  791  792  793  794  795  796  797  798\n",
      "  799  800  801  802  803  804  805  806  807  808  809  810  811  812  813\n",
      "  814  815  816  817  818  819  820  821  822  823  824  825  826  827  828\n",
      "  829  830  831  832  833  834  835  836  837  838  839  840  841  842  843\n",
      "  844  845  846  847  848  849  850  851  852  853  854  855  856  857  858\n",
      "  859  860  861  862  863  864  865  866  942  943  944  945  946  947  948\n",
      "  949  950  951  952  953  954  955  956  957  958  959  960  961  962  963\n",
      "  964  965  966  967  968  969  970  971  972  973  974  975  976  977  978\n",
      "  979  980  981  982  983  984  985  986  987  988  989  990  991  992  993\n",
      "  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008\n",
      " 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023\n",
      " 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038\n",
      " 1039 1040 1041 1042]\n",
      "574\n"
     ]
    }
   ],
   "source": [
    "# handpicking features\n",
    "\n",
    "# feature groups:\n",
    "#       1 - Raw Signal Statistics\n",
    "#       2 - Raw Signal Correlation Coefficients\n",
    "#       3 - Raw Signal 5s FFT bins\n",
    "#       4 - Raw Signal 1s FFT bins\n",
    "#\t\t5 - Derivative Statistics\n",
    "#\t\t6 - Derivative 5s FFT bins\n",
    "#\t\t7 - Derivative 1s FFT bins\n",
    "#\t\t8 - Resultant Vector and Magnitude \n",
    "#\t\t9 - Angle Statistics (ArcTan)\n",
    "#\t\t10 - Entropies\n",
    "#\t\t11 - Raw Signal Cross Products\n",
    "#\t\t12 - Derivative Cross Products\n",
    "#\t\t13 - Raw Signal Statistics on 1s FFT bins\n",
    "#\t\t14 - Raw Signal Entropies on 1s FFT bins\n",
    "#\t\t15 - Raw Signal Statistics on 1s binned signal energy\n",
    "#\t\t16 - Derivative Statistics on 1s FFT bins\n",
    "#\t\t17 - Derivative Entropies on 1s FFT bins\n",
    "#\t\t18 - Barometer\n",
    "\n",
    "features_to_use = eng.getFeatureInds(matlab.logical([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]))\n",
    "\n",
    "features_to_use = np.array(features_to_use)\n",
    "features_to_use = [y for x in features_to_use for y in x] # flatten array\n",
    "features_to_use = np.array(features_to_use)\n",
    "\n",
    "features = features[features_to_use]\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 388 (0.018619)\n",
      "2. feature 988 (0.018204)\n",
      "3. feature 990 (0.016771)\n",
      "4. feature 956 (0.014366)\n",
      "5. feature 386 (0.013826)\n",
      "6. feature 989 (0.013757)\n",
      "7. feature 1045 (0.013002)\n",
      "8. feature 1071 (0.012502)\n",
      "9. feature 1121 (0.012065)\n",
      "10. feature 387 (0.011970)\n",
      "11. feature 609 (0.009965)\n",
      "12. feature 1011 (0.009593)\n",
      "13. feature 1120 (0.008769)\n",
      "14. feature 965 (0.008477)\n",
      "15. feature 966 (0.008219)\n",
      "16. feature 183 (0.008186)\n",
      "17. feature 1144 (0.008126)\n",
      "18. feature 1146 (0.008033)\n",
      "19. feature 1010 (0.007304)\n",
      "20. feature 955 (0.007002)\n",
      "21. feature 1171 (0.006833)\n",
      "22. feature 1046 (0.006769)\n",
      "23. feature 1119 (0.006487)\n",
      "24. feature 1070 (0.006081)\n",
      "25. feature 985 (0.006077)\n",
      "26. feature 787 (0.006066)\n",
      "27. feature 184 (0.006012)\n",
      "28. feature 1190 (0.005883)\n",
      "29. feature 946 (0.005829)\n",
      "30. feature 945 (0.005799)\n",
      "31. feature 625 (0.005368)\n",
      "32. feature 599 (0.005273)\n",
      "33. feature 1203 (0.005130)\n",
      "34. feature 786 (0.005107)\n",
      "35. feature 1145 (0.005024)\n",
      "36. feature 627 (0.004837)\n",
      "37. feature 1196 (0.004281)\n",
      "38. feature 971 (0.004272)\n",
      "39. feature 1191 (0.004268)\n",
      "40. feature 1201 (0.004168)\n",
      "41. feature 964 (0.004141)\n",
      "42. feature 957 (0.004000)\n",
      "43. feature 1095 (0.003979)\n",
      "44. feature 944 (0.003974)\n",
      "45. feature 785 (0.003893)\n",
      "46. feature 1009 (0.003875)\n",
      "47. feature 492 (0.003810)\n",
      "48. feature 970 (0.003808)\n",
      "49. feature 1169 (0.003799)\n",
      "50. feature 1193 (0.003645)\n",
      "51. feature 343 (0.003641)\n",
      "52. feature 789 (0.003610)\n",
      "53. feature 517 (0.003605)\n",
      "54. feature 1031 (0.003562)\n",
      "55. feature 569 (0.003537)\n",
      "56. feature 940 (0.003481)\n",
      "57. feature 1170 (0.003475)\n",
      "58. feature 996 (0.003464)\n",
      "59. feature 1094 (0.003408)\n",
      "60. feature 573 (0.003357)\n",
      "61. feature 1012 (0.003282)\n",
      "62. feature 519 (0.003279)\n",
      "63. feature 1018 (0.003271)\n",
      "64. feature 979 (0.003238)\n",
      "65. feature 986 (0.003187)\n",
      "66. feature 601 (0.003107)\n",
      "67. feature 987 (0.003096)\n",
      "68. feature 494 (0.003081)\n",
      "69. feature 608 (0.002995)\n",
      "70. feature 1122 (0.002954)\n",
      "71. feature 1030 (0.002941)\n",
      "72. feature 1044 (0.002924)\n",
      "73. feature 943 (0.002873)\n",
      "74. feature 779 (0.002857)\n",
      "75. feature 972 (0.002852)\n",
      "76. feature 1047 (0.002832)\n",
      "77. feature 1069 (0.002796)\n",
      "78. feature 610 (0.002756)\n",
      "79. feature 1032 (0.002735)\n",
      "80. feature 442 (0.002676)\n",
      "81. feature 954 (0.002663)\n",
      "82. feature 589 (0.002642)\n",
      "83. feature 941 (0.002609)\n",
      "84. feature 185 (0.002584)\n",
      "85. feature 341 (0.002562)\n",
      "86. feature 967 (0.002550)\n",
      "87. feature 549 (0.002545)\n",
      "88. feature 968 (0.002537)\n",
      "89. feature 949 (0.002424)\n",
      "90. feature 636 (0.002397)\n",
      "91. feature 383 (0.002346)\n",
      "92. feature 1001 (0.002343)\n",
      "93. feature 1097 (0.002324)\n",
      "94. feature 654 (0.002299)\n",
      "95. feature 574 (0.002290)\n",
      "96. feature 788 (0.002289)\n",
      "97. feature 524 (0.002278)\n",
      "98. feature 1096 (0.002263)\n",
      "99. feature 568 (0.002260)\n",
      "100. feature 1072 (0.002249)\n",
      "101. feature 526 (0.002225)\n",
      "102. feature 1014 (0.002192)\n",
      "103. feature 1147 (0.002168)\n",
      "104. feature 1000 (0.002149)\n",
      "105. feature 1200 (0.002144)\n",
      "106. feature 444 (0.002113)\n",
      "107. feature 591 (0.002106)\n",
      "108. feature 468 (0.002103)\n",
      "109. feature 543 (0.002095)\n",
      "110. feature 626 (0.002091)\n",
      "111. feature 994 (0.002039)\n",
      "112. feature 1013 (0.002027)\n",
      "113. feature 338 (0.002016)\n",
      "114. feature 1026 (0.002007)\n",
      "115. feature 23 (0.002001)\n",
      "116. feature 571 (0.001994)\n",
      "117. feature 1035 (0.001971)\n",
      "118. feature 544 (0.001957)\n",
      "119. feature 1195 (0.001951)\n",
      "120. feature 1204 (0.001928)\n",
      "121. feature 422 (0.001919)\n",
      "122. feature 1065 (0.001919)\n",
      "123. feature 520 (0.001881)\n",
      "124. feature 495 (0.001835)\n",
      "125. feature 1019 (0.001799)\n",
      "126. feature 798 (0.001789)\n",
      "127. feature 1066 (0.001774)\n",
      "128. feature 1139 (0.001758)\n",
      "129. feature 803 (0.001751)\n",
      "130. feature 641 (0.001731)\n",
      "131. feature 428 (0.001725)\n",
      "132. feature 575 (0.001704)\n",
      "133. feature 498 (0.001696)\n",
      "134. feature 570 (0.001679)\n",
      "135. feature 1033 (0.001661)\n",
      "136. feature 760 (0.001658)\n",
      "137. feature 1002 (0.001655)\n",
      "138. feature 801 (0.001650)\n",
      "139. feature 493 (0.001627)\n",
      "140. feature 423 (0.001617)\n",
      "141. feature 780 (0.001612)\n",
      "142. feature 1172 (0.001602)\n",
      "143. feature 594 (0.001602)\n",
      "144. feature 443 (0.001590)\n",
      "145. feature 1040 (0.001589)\n",
      "146. feature 827 (0.001588)\n",
      "147. feature 1028 (0.001584)\n",
      "148. feature 1126 (0.001569)\n",
      "149. feature 550 (0.001567)\n",
      "150. feature 976 (0.001566)\n",
      "151. feature 980 (0.001562)\n",
      "152. feature 1128 (0.001549)\n",
      "153. feature 995 (0.001546)\n",
      "154. feature 518 (0.001530)\n",
      "155. feature 810 (0.001515)\n",
      "156. feature 948 (0.001500)\n",
      "157. feature 445 (0.001495)\n",
      "158. feature 1020 (0.001487)\n",
      "159. feature 828 (0.001485)\n",
      "160. feature 429 (0.001480)\n",
      "161. feature 951 (0.001477)\n",
      "162. feature 384 (0.001468)\n",
      "163. feature 714 (0.001461)\n",
      "164. feature 1024 (0.001461)\n",
      "165. feature 469 (0.001461)\n",
      "166. feature 603 (0.001460)\n",
      "167. feature 1141 (0.001459)\n",
      "168. feature 628 (0.001435)\n",
      "169. feature 340 (0.001428)\n",
      "170. feature 645 (0.001425)\n",
      "171. feature 1048 (0.001420)\n",
      "172. feature 792 (0.001410)\n",
      "173. feature 978 (0.001402)\n",
      "174. feature 567 (0.001393)\n",
      "175. feature 1198 (0.001382)\n",
      "176. feature 467 (0.001376)\n",
      "177. feature 759 (0.001376)\n",
      "178. feature 815 (0.001369)\n",
      "179. feature 806 (0.001369)\n",
      "180. feature 638 (0.001357)\n",
      "181. feature 545 (0.001344)\n",
      "182. feature 804 (0.001342)\n",
      "183. feature 969 (0.001341)\n",
      "184. feature 1038 (0.001320)\n",
      "185. feature 650 (0.001318)\n",
      "186. feature 1116 (0.001303)\n",
      "187. feature 1053 (0.001300)\n",
      "188. feature 1153 (0.001299)\n",
      "189. feature 656 (0.001289)\n",
      "190. feature 647 (0.001281)\n",
      "191. feature 1025 (0.001278)\n",
      "192. feature 1148 (0.001274)\n",
      "193. feature 1123 (0.001268)\n",
      "194. feature 1034 (0.001259)\n",
      "195. feature 745 (0.001258)\n",
      "196. feature 633 (0.001251)\n",
      "197. feature 424 (0.001242)\n",
      "198. feature 474 (0.001241)\n",
      "199. feature 408 (0.001239)\n",
      "200. feature 598 (0.001215)\n",
      "201. feature 1115 (0.001208)\n",
      "202. feature 398 (0.001200)\n",
      "203. feature 352 (0.001184)\n",
      "204. feature 991 (0.001178)\n",
      "205. feature 639 (0.001175)\n",
      "206. feature 818 (0.001163)\n",
      "207. feature 521 (0.001162)\n",
      "208. feature 354 (0.001133)\n",
      "209. feature 800 (0.001129)\n",
      "210. feature 646 (0.001115)\n",
      "211. feature 1142 (0.001110)\n",
      "212. feature 380 (0.001108)\n",
      "213. feature 699 (0.001082)\n",
      "214. feature 657 (0.001079)\n",
      "215. feature 1140 (0.001063)\n",
      "216. feature 973 (0.001059)\n",
      "217. feature 342 (0.001058)\n",
      "218. feature 648 (0.001054)\n",
      "219. feature 619 (0.001048)\n",
      "220. feature 345 (0.001038)\n",
      "221. feature 546 (0.001036)\n",
      "222. feature 430 (0.001034)\n",
      "223. feature 825 (0.001029)\n",
      "224. feature 630 (0.001027)\n",
      "225. feature 1194 (0.001023)\n",
      "226. feature 790 (0.001019)\n",
      "227. feature 1036 (0.001015)\n",
      "228. feature 819 (0.001014)\n",
      "229. feature 1152 (0.001004)\n",
      "230. feature 793 (0.001001)\n",
      "231. feature 347 (0.000999)\n",
      "232. feature 698 (0.000993)\n",
      "233. feature 1073 (0.000992)\n",
      "234. feature 947 (0.000985)\n",
      "235. feature 795 (0.000984)\n",
      "236. feature 962 (0.000981)\n",
      "237. feature 665 (0.000974)\n",
      "238. feature 576 (0.000971)\n",
      "239. feature 1189 (0.000969)\n",
      "240. feature 1076 (0.000962)\n",
      "241. feature 177 (0.000956)\n",
      "242. feature 662 (0.000948)\n",
      "243. feature 600 (0.000946)\n",
      "244. feature 836 (0.000931)\n",
      "245. feature 821 (0.000931)\n",
      "246. feature 1075 (0.000930)\n",
      "247. feature 672 (0.000926)\n",
      "248. feature 497 (0.000916)\n",
      "249. feature 353 (0.000912)\n",
      "250. feature 385 (0.000907)\n",
      "251. feature 523 (0.000899)\n",
      "252. feature 977 (0.000896)\n",
      "253. feature 103 (0.000894)\n",
      "254. feature 663 (0.000892)\n",
      "255. feature 339 (0.000874)\n",
      "256. feature 842 (0.000873)\n",
      "257. feature 668 (0.000869)\n",
      "258. feature 1127 (0.000857)\n",
      "259. feature 816 (0.000845)\n",
      "260. feature 417 (0.000828)\n",
      "261. feature 837 (0.000827)\n",
      "262. feature 355 (0.000824)\n",
      "263. feature 1027 (0.000814)\n",
      "264. feature 1151 (0.000811)\n",
      "265. feature 807 (0.000811)\n",
      "266. feature 1051 (0.000806)\n",
      "267. feature 1089 (0.000804)\n",
      "268. feature 411 (0.000803)\n",
      "269. feature 1078 (0.000802)\n",
      "270. feature 1052 (0.000800)\n",
      "271. feature 13 (0.000799)\n",
      "272. feature 822 (0.000799)\n",
      "273. feature 982 (0.000798)\n",
      "274. feature 436 (0.000797)\n",
      "275. feature 6 (0.000790)\n",
      "276. feature 909 (0.000782)\n",
      "277. feature 1125 (0.000776)\n",
      "278. feature 418 (0.000771)\n",
      "279. feature 831 (0.000764)\n",
      "280. feature 269 (0.000759)\n",
      "281. feature 346 (0.000757)\n",
      "282. feature 983 (0.000756)\n",
      "283. feature 942 (0.000752)\n",
      "284. feature 585 (0.000747)\n",
      "285. feature 631 (0.000746)\n",
      "286. feature 425 (0.000742)\n",
      "287. feature 531 (0.000738)\n",
      "288. feature 642 (0.000735)\n",
      "289. feature 635 (0.000732)\n",
      "290. feature 813 (0.000718)\n",
      "291. feature 781 (0.000713)\n",
      "292. feature 542 (0.000708)\n",
      "293. feature 1163 (0.000708)\n",
      "294. feature 791 (0.000707)\n",
      "295. feature 1042 (0.000705)\n",
      "296. feature 412 (0.000704)\n",
      "297. feature 1041 (0.000703)\n",
      "298. feature 938 (0.000699)\n",
      "299. feature 1150 (0.000698)\n",
      "300. feature 661 (0.000690)\n",
      "301. feature 809 (0.000686)\n",
      "302. feature 653 (0.000685)\n",
      "303. feature 830 (0.000684)\n",
      "304. feature 671 (0.000684)\n",
      "305. feature 618 (0.000683)\n",
      "306. feature 12 (0.000682)\n",
      "307. feature 824 (0.000675)\n",
      "308. feature 632 (0.000668)\n",
      "309. feature 1064 (0.000664)\n",
      "310. feature 45 (0.000663)\n",
      "311. feature 393 (0.000657)\n",
      "312. feature 268 (0.000655)\n",
      "313. feature 693 (0.000651)\n",
      "314. feature 239 (0.000650)\n",
      "315. feature 221 (0.000639)\n",
      "316. feature 593 (0.000631)\n",
      "317. feature 643 (0.000631)\n",
      "318. feature 1037 (0.000628)\n",
      "319. feature 783 (0.000627)\n",
      "320. feature 240 (0.000624)\n",
      "321. feature 21 (0.000623)\n",
      "322. feature 834 (0.000616)\n",
      "323. feature 799 (0.000613)\n",
      "324. feature 812 (0.000613)\n",
      "325. feature 1101 (0.000612)\n",
      "326. feature 1174 (0.000609)\n",
      "327. feature 833 (0.000604)\n",
      "328. feature 677 (0.000602)\n",
      "329. feature 432 (0.000599)\n",
      "330. feature 660 (0.000598)\n",
      "331. feature 534 (0.000597)\n",
      "332. feature 496 (0.000596)\n",
      "333. feature 175 (0.000594)\n",
      "334. feature 38 (0.000590)\n",
      "335. feature 499 (0.000587)\n",
      "336. feature 1114 (0.000582)\n",
      "337. feature 349 (0.000581)\n",
      "338. feature 189 (0.000581)\n",
      "339. feature 100 (0.000579)\n",
      "340. feature 106 (0.000578)\n",
      "341. feature 265 (0.000576)\n",
      "342. feature 337 (0.000576)\n",
      "343. feature 596 (0.000572)\n",
      "344. feature 644 (0.000571)\n",
      "345. feature 1100 (0.000570)\n",
      "346. feature 666 (0.000570)\n",
      "347. feature 950 (0.000570)\n",
      "348. feature 19 (0.000567)\n",
      "349. feature 400 (0.000566)\n",
      "350. feature 588 (0.000565)\n",
      "351. feature 186 (0.000563)\n",
      "352. feature 449 (0.000563)\n",
      "353. feature 640 (0.000562)\n",
      "354. feature 420 (0.000560)\n",
      "355. feature 687 (0.000557)\n",
      "356. feature 1177 (0.000555)\n",
      "357. feature 275 (0.000552)\n",
      "358. feature 271 (0.000545)\n",
      "359. feature 669 (0.000544)\n",
      "360. feature 1029 (0.000543)\n",
      "361. feature 394 (0.000540)\n",
      "362. feature 651 (0.000536)\n",
      "363. feature 237 (0.000535)\n",
      "364. feature 851 (0.000534)\n",
      "365. feature 875 (0.000531)\n",
      "366. feature 229 (0.000530)\n",
      "367. feature 655 (0.000527)\n",
      "368. feature 264 (0.000526)\n",
      "369. feature 437 (0.000526)\n",
      "370. feature 41 (0.000525)\n",
      "371. feature 877 (0.000519)\n",
      "372. feature 606 (0.000518)\n",
      "373. feature 1090 (0.000517)\n",
      "374. feature 848 (0.000509)\n",
      "375. feature 602 (0.000509)\n",
      "376. feature 381 (0.000508)\n",
      "377. feature 525 (0.000504)\n",
      "378. feature 595 (0.000502)\n",
      "379. feature 536 (0.000502)\n",
      "380. feature 473 (0.000500)\n",
      "381. feature 1102 (0.000500)\n",
      "382. feature 1067 (0.000497)\n",
      "383. feature 1124 (0.000496)\n",
      "384. feature 587 (0.000490)\n",
      "385. feature 1205 (0.000488)\n",
      "386. feature 777 (0.000486)\n",
      "387. feature 1166 (0.000486)\n",
      "388. feature 684 (0.000482)\n",
      "389. feature 539 (0.000482)\n",
      "390. feature 344 (0.000479)\n",
      "391. feature 796 (0.000479)\n",
      "392. feature 61 (0.000479)\n",
      "393. feature 974 (0.000478)\n",
      "394. feature 11 (0.000474)\n",
      "395. feature 963 (0.000474)\n",
      "396. feature 218 (0.000472)\n",
      "397. feature 649 (0.000471)\n",
      "398. feature 416 (0.000466)\n",
      "399. feature 659 (0.000466)\n",
      "400. feature 561 (0.000464)\n",
      "401. feature 664 (0.000463)\n",
      "402. feature 1050 (0.000462)\n",
      "403. feature 1117 (0.000460)\n",
      "404. feature 404 (0.000458)\n",
      "405. feature 246 (0.000458)\n",
      "406. feature 855 (0.000458)\n",
      "407. feature 272 (0.000456)\n",
      "408. feature 471 (0.000452)\n",
      "409. feature 206 (0.000452)\n",
      "410. feature 101 (0.000451)\n",
      "411. feature 1176 (0.000447)\n",
      "412. feature 840 (0.000446)\n",
      "413. feature 857 (0.000445)\n",
      "414. feature 696 (0.000445)\n",
      "415. feature 820 (0.000445)\n",
      "416. feature 805 (0.000443)\n",
      "417. feature 475 (0.000443)\n",
      "418. feature 431 (0.000442)\n",
      "419. feature 535 (0.000441)\n",
      "420. feature 776 (0.000441)\n",
      "421. feature 975 (0.000441)\n",
      "422. feature 612 (0.000438)\n",
      "423. feature 249 (0.000437)\n",
      "424. feature 981 (0.000436)\n",
      "425. feature 695 (0.000435)\n",
      "426. feature 917 (0.000433)\n",
      "427. feature 348 (0.000433)\n",
      "428. feature 74 (0.000430)\n",
      "429. feature 849 (0.000429)\n",
      "430. feature 1149 (0.000423)\n",
      "431. feature 1003 (0.000423)\n",
      "432. feature 243 (0.000422)\n",
      "433. feature 620 (0.000421)\n",
      "434. feature 236 (0.000421)\n",
      "435. feature 7 (0.000420)\n",
      "436. feature 1199 (0.000419)\n",
      "437. feature 1077 (0.000415)\n",
      "438. feature 778 (0.000414)\n",
      "439. feature 826 (0.000413)\n",
      "440. feature 1091 (0.000411)\n",
      "441. feature 378 (0.000410)\n",
      "442. feature 63 (0.000410)\n",
      "443. feature 395 (0.000410)\n",
      "444. feature 551 (0.000409)\n",
      "445. feature 961 (0.000409)\n",
      "446. feature 102 (0.000408)\n",
      "447. feature 37 (0.000406)\n",
      "448. feature 540 (0.000406)\n",
      "449. feature 670 (0.000405)\n",
      "450. feature 207 (0.000404)\n",
      "451. feature 839 (0.000403)\n",
      "452. feature 894 (0.000402)\n",
      "453. feature 658 (0.000401)\n",
      "454. feature 998 (0.000400)\n",
      "455. feature 808 (0.000396)\n",
      "456. feature 463 (0.000394)\n",
      "457. feature 20 (0.000394)\n",
      "458. feature 1092 (0.000390)\n",
      "459. feature 1197 (0.000388)\n",
      "460. feature 274 (0.000387)\n",
      "461. feature 195 (0.000387)\n",
      "462. feature 911 (0.000384)\n",
      "463. feature 87 (0.000381)\n",
      "464. feature 853 (0.000380)\n",
      "465. feature 137 (0.000378)\n",
      "466. feature 1103 (0.000378)\n",
      "467. feature 1005 (0.000376)\n",
      "468. feature 34 (0.000375)\n",
      "469. feature 634 (0.000375)\n",
      "470. feature 811 (0.000375)\n",
      "471. feature 72 (0.000371)\n",
      "472. feature 359 (0.000370)\n",
      "473. feature 382 (0.000370)\n",
      "474. feature 226 (0.000365)\n",
      "475. feature 616 (0.000365)\n",
      "476. feature 446 (0.000364)\n",
      "477. feature 675 (0.000364)\n",
      "478. feature 18 (0.000364)\n",
      "479. feature 814 (0.000362)\n",
      "480. feature 817 (0.000361)\n",
      "481. feature 1137 (0.000360)\n",
      "482. feature 202 (0.000360)\n",
      "483. feature 215 (0.000360)\n",
      "484. feature 566 (0.000359)\n",
      "485. feature 908 (0.000359)\n",
      "486. feature 555 (0.000358)\n",
      "487. feature 615 (0.000356)\n",
      "488. feature 992 (0.000354)\n",
      "489. feature 712 (0.000353)\n",
      "490. feature 227 (0.000353)\n",
      "491. feature 90 (0.000353)\n",
      "492. feature 267 (0.000351)\n",
      "493. feature 470 (0.000351)\n",
      "494. feature 1039 (0.000351)\n",
      "495. feature 414 (0.000350)\n",
      "496. feature 8 (0.000350)\n",
      "497. feature 225 (0.000350)\n",
      "498. feature 53 (0.000349)\n",
      "499. feature 403 (0.000348)\n",
      "500. feature 81 (0.000348)\n",
      "501. feature 749 (0.000348)\n",
      "502. feature 26 (0.000347)\n",
      "503. feature 586 (0.000347)\n",
      "504. feature 958 (0.000346)\n",
      "505. feature 1016 (0.000346)\n",
      "506. feature 266 (0.000345)\n",
      "507. feature 711 (0.000344)\n",
      "508. feature 415 (0.000344)\n",
      "509. feature 358 (0.000343)\n",
      "510. feature 296 (0.000342)\n",
      "511. feature 881 (0.000342)\n",
      "512. feature 203 (0.000340)\n",
      "513. feature 42 (0.000338)\n",
      "514. feature 488 (0.000337)\n",
      "515. feature 1017 (0.000334)\n",
      "516. feature 262 (0.000333)\n",
      "517. feature 512 (0.000333)\n",
      "518. feature 1164 (0.000333)\n",
      "519. feature 1021 (0.000333)\n",
      "520. feature 652 (0.000332)\n",
      "521. feature 462 (0.000332)\n",
      "522. feature 392 (0.000332)\n",
      "523. feature 866 (0.000331)\n",
      "524. feature 399 (0.000330)\n",
      "525. feature 624 (0.000330)\n",
      "526. feature 590 (0.000330)\n",
      "527. feature 873 (0.000328)\n",
      "528. feature 438 (0.000328)\n",
      "529. feature 637 (0.000328)\n",
      "530. feature 3 (0.000327)\n",
      "531. feature 621 (0.000326)\n",
      "532. feature 5 (0.000326)\n",
      "533. feature 190 (0.000325)\n",
      "534. feature 250 (0.000323)\n",
      "535. feature 213 (0.000322)\n",
      "536. feature 746 (0.000322)\n",
      "537. feature 410 (0.000322)\n",
      "538. feature 912 (0.000321)\n",
      "539. feature 2 (0.000321)\n",
      "540. feature 487 (0.000319)\n",
      "541. feature 32 (0.000318)\n",
      "542. feature 230 (0.000318)\n",
      "543. feature 270 (0.000317)\n",
      "544. feature 775 (0.000317)\n",
      "545. feature 937 (0.000316)\n",
      "546. feature 674 (0.000316)\n",
      "547. feature 219 (0.000315)\n",
      "548. feature 1138 (0.000315)\n",
      "549. feature 959 (0.000315)\n",
      "550. feature 426 (0.000314)\n",
      "551. feature 703 (0.000312)\n",
      "552. feature 1136 (0.000312)\n",
      "553. feature 179 (0.000312)\n",
      "554. feature 224 (0.000311)\n",
      "555. feature 1178 (0.000311)\n",
      "556. feature 252 (0.000311)\n",
      "557. feature 874 (0.000310)\n",
      "558. feature 96 (0.000310)\n",
      "559. feature 210 (0.000309)\n",
      "560. feature 514 (0.000309)\n",
      "561. feature 371 (0.000307)\n",
      "562. feature 597 (0.000306)\n",
      "563. feature 58 (0.000304)\n",
      "564. feature 377 (0.000302)\n",
      "565. feature 333 (0.000301)\n",
      "566. feature 157 (0.000301)\n",
      "567. feature 233 (0.000301)\n",
      "568. feature 1167 (0.000301)\n",
      "569. feature 376 (0.000300)\n",
      "570. feature 326 (0.000300)\n",
      "571. feature 667 (0.000300)\n",
      "572. feature 283 (0.000298)\n",
      "573. feature 953 (0.000297)\n",
      "574. feature 435 (0.000297)\n",
      "575. feature 581 (0.000297)\n",
      "576. feature 273 (0.000296)\n",
      "577. feature 180 (0.000296)\n",
      "578. feature 629 (0.000296)\n",
      "579. feature 747 (0.000295)\n",
      "580. feature 768 (0.000294)\n",
      "581. feature 205 (0.000293)\n",
      "582. feature 254 (0.000293)\n",
      "583. feature 681 (0.000293)\n",
      "584. feature 160 (0.000292)\n",
      "585. feature 29 (0.000292)\n",
      "586. feature 324 (0.000291)\n",
      "587. feature 209 (0.000290)\n",
      "588. feature 673 (0.000290)\n",
      "589. feature 49 (0.000288)\n",
      "590. feature 396 (0.000288)\n",
      "591. feature 710 (0.000287)\n",
      "592. feature 513 (0.000286)\n",
      "593. feature 914 (0.000286)\n",
      "594. feature 174 (0.000285)\n",
      "595. feature 357 (0.000285)\n",
      "596. feature 484 (0.000284)\n",
      "597. feature 25 (0.000283)\n",
      "598. feature 846 (0.000282)\n",
      "599. feature 934 (0.000282)\n",
      "600. feature 447 (0.000282)\n",
      "601. feature 201 (0.000281)\n",
      "602. feature 729 (0.000281)\n",
      "603. feature 22 (0.000279)\n",
      "604. feature 1006 (0.000278)\n",
      "605. feature 214 (0.000278)\n",
      "606. feature 162 (0.000277)\n",
      "607. feature 14 (0.000276)\n",
      "608. feature 730 (0.000276)\n",
      "609. feature 899 (0.000275)\n",
      "610. feature 1187 (0.000275)\n",
      "611. feature 351 (0.000274)\n",
      "612. feature 614 (0.000273)\n",
      "613. feature 199 (0.000273)\n",
      "614. feature 196 (0.000273)\n",
      "615. feature 931 (0.000271)\n",
      "616. feature 984 (0.000271)\n",
      "617. feature 66 (0.000270)\n",
      "618. feature 876 (0.000269)\n",
      "619. feature 336 (0.000268)\n",
      "620. feature 75 (0.000267)\n",
      "621. feature 235 (0.000267)\n",
      "622. feature 563 (0.000267)\n",
      "623. feature 784 (0.000267)\n",
      "624. feature 538 (0.000266)\n",
      "625. feature 897 (0.000265)\n",
      "626. feature 216 (0.000265)\n",
      "627. feature 1023 (0.000265)\n",
      "628. feature 59 (0.000265)\n",
      "629. feature 960 (0.000264)\n",
      "630. feature 690 (0.000264)\n",
      "631. feature 547 (0.000264)\n",
      "632. feature 56 (0.000263)\n",
      "633. feature 332 (0.000262)\n",
      "634. feature 390 (0.000262)\n",
      "635. feature 843 (0.000262)\n",
      "636. feature 419 (0.000262)\n",
      "637. feature 1162 (0.000262)\n",
      "638. feature 176 (0.000262)\n",
      "639. feature 1165 (0.000260)\n",
      "640. feature 852 (0.000260)\n",
      "641. feature 860 (0.000259)\n",
      "642. feature 200 (0.000259)\n",
      "643. feature 36 (0.000258)\n",
      "644. feature 685 (0.000258)\n",
      "645. feature 999 (0.000258)\n",
      "646. feature 413 (0.000257)\n",
      "647. feature 841 (0.000257)\n",
      "648. feature 1168 (0.000256)\n",
      "649. feature 723 (0.000256)\n",
      "650. feature 373 (0.000256)\n",
      "651. feature 76 (0.000256)\n",
      "652. feature 427 (0.000255)\n",
      "653. feature 607 (0.000254)\n",
      "654. feature 1202 (0.000254)\n",
      "655. feature 797 (0.000253)\n",
      "656. feature 368 (0.000253)\n",
      "657. feature 109 (0.000253)\n",
      "658. feature 476 (0.000252)\n",
      "659. feature 709 (0.000252)\n",
      "660. feature 678 (0.000249)\n",
      "661. feature 197 (0.000248)\n",
      "662. feature 98 (0.000248)\n",
      "663. feature 329 (0.000247)\n",
      "664. feature 752 (0.000247)\n",
      "665. feature 192 (0.000247)\n",
      "666. feature 24 (0.000247)\n",
      "667. feature 705 (0.000247)\n",
      "668. feature 548 (0.000247)\n",
      "669. feature 935 (0.000246)\n",
      "670. feature 756 (0.000246)\n",
      "671. feature 220 (0.000246)\n",
      "672. feature 1093 (0.000246)\n",
      "673. feature 688 (0.000246)\n",
      "674. feature 57 (0.000246)\n",
      "675. feature 178 (0.000245)\n",
      "676. feature 325 (0.000245)\n",
      "677. feature 164 (0.000244)\n",
      "678. feature 194 (0.000244)\n",
      "679. feature 193 (0.000244)\n",
      "680. feature 1007 (0.000244)\n",
      "681. feature 260 (0.000243)\n",
      "682. feature 1087 (0.000243)\n",
      "683. feature 556 (0.000243)\n",
      "684. feature 1118 (0.000242)\n",
      "685. feature 680 (0.000242)\n",
      "686. feature 450 (0.000242)\n",
      "687. feature 318 (0.000242)\n",
      "688. feature 4 (0.000241)\n",
      "689. feature 838 (0.000241)\n",
      "690. feature 116 (0.000240)\n",
      "691. feature 421 (0.000239)\n",
      "692. feature 753 (0.000239)\n",
      "693. feature 879 (0.000239)\n",
      "694. feature 65 (0.000239)\n",
      "695. feature 872 (0.000238)\n",
      "696. feature 309 (0.000238)\n",
      "697. feature 389 (0.000237)\n",
      "698. feature 737 (0.000237)\n",
      "699. feature 257 (0.000237)\n",
      "700. feature 391 (0.000236)\n",
      "701. feature 1207 (0.000236)\n",
      "702. feature 364 (0.000235)\n",
      "703. feature 903 (0.000235)\n",
      "704. feature 750 (0.000235)\n",
      "705. feature 491 (0.000234)\n",
      "706. feature 622 (0.000233)\n",
      "707. feature 16 (0.000232)\n",
      "708. feature 161 (0.000231)\n",
      "709. feature 862 (0.000230)\n",
      "710. feature 379 (0.000230)\n",
      "711. feature 727 (0.000230)\n",
      "712. feature 30 (0.000230)\n",
      "713. feature 794 (0.000230)\n",
      "714. feature 248 (0.000228)\n",
      "715. feature 1206 (0.000226)\n",
      "716. feature 707 (0.000226)\n",
      "717. feature 279 (0.000225)\n",
      "718. feature 141 (0.000225)\n",
      "719. feature 766 (0.000225)\n",
      "720. feature 401 (0.000225)\n",
      "721. feature 1210 (0.000225)\n",
      "722. feature 697 (0.000225)\n",
      "723. feature 700 (0.000223)\n",
      "724. feature 276 (0.000223)\n",
      "725. feature 715 (0.000222)\n",
      "726. feature 323 (0.000222)\n",
      "727. feature 406 (0.000222)\n",
      "728. feature 31 (0.000221)\n",
      "729. feature 88 (0.000220)\n",
      "730. feature 253 (0.000220)\n",
      "731. feature 453 (0.000220)\n",
      "732. feature 99 (0.000219)\n",
      "733. feature 107 (0.000219)\n",
      "734. feature 572 (0.000218)\n",
      "735. feature 211 (0.000218)\n",
      "736. feature 0 (0.000218)\n",
      "737. feature 39 (0.000218)\n",
      "738. feature 307 (0.000217)\n",
      "739. feature 558 (0.000217)\n",
      "740. feature 222 (0.000217)\n",
      "741. feature 869 (0.000217)\n",
      "742. feature 605 (0.000217)\n",
      "743. feature 880 (0.000216)\n",
      "744. feature 256 (0.000216)\n",
      "745. feature 564 (0.000216)\n",
      "746. feature 55 (0.000215)\n",
      "747. feature 231 (0.000215)\n",
      "748. feature 871 (0.000215)\n",
      "749. feature 611 (0.000215)\n",
      "750. feature 742 (0.000214)\n",
      "751. feature 456 (0.000214)\n",
      "752. feature 321 (0.000214)\n",
      "753. feature 119 (0.000213)\n",
      "754. feature 708 (0.000212)\n",
      "755. feature 62 (0.000212)\n",
      "756. feature 580 (0.000211)\n",
      "757. feature 870 (0.000210)\n",
      "758. feature 692 (0.000210)\n",
      "759. feature 166 (0.000210)\n",
      "760. feature 1074 (0.000209)\n",
      "761. feature 142 (0.000209)\n",
      "762. feature 762 (0.000209)\n",
      "763. feature 579 (0.000208)\n",
      "764. feature 122 (0.000208)\n",
      "765. feature 290 (0.000208)\n",
      "766. feature 397 (0.000208)\n",
      "767. feature 907 (0.000208)\n",
      "768. feature 35 (0.000207)\n",
      "769. feature 331 (0.000206)\n",
      "770. feature 1158 (0.000205)\n",
      "771. feature 1188 (0.000205)\n",
      "772. feature 1133 (0.000205)\n",
      "773. feature 617 (0.000204)\n",
      "774. feature 402 (0.000204)\n",
      "775. feature 407 (0.000204)\n",
      "776. feature 370 (0.000204)\n",
      "777. feature 844 (0.000204)\n",
      "778. feature 319 (0.000204)\n",
      "779. feature 212 (0.000204)\n",
      "780. feature 770 (0.000204)\n",
      "781. feature 613 (0.000203)\n",
      "782. feature 802 (0.000203)\n",
      "783. feature 900 (0.000203)\n",
      "784. feature 362 (0.000203)\n",
      "785. feature 434 (0.000203)\n",
      "786. feature 128 (0.000202)\n",
      "787. feature 865 (0.000201)\n",
      "788. feature 92 (0.000201)\n",
      "789. feature 823 (0.000199)\n",
      "790. feature 43 (0.000199)\n",
      "791. feature 451 (0.000198)\n",
      "792. feature 44 (0.000198)\n",
      "793. feature 728 (0.000197)\n",
      "794. feature 926 (0.000197)\n",
      "795. feature 713 (0.000197)\n",
      "796. feature 702 (0.000196)\n",
      "797. feature 85 (0.000196)\n",
      "798. feature 258 (0.000196)\n",
      "799. feature 71 (0.000196)\n",
      "800. feature 335 (0.000195)\n",
      "801. feature 120 (0.000194)\n",
      "802. feature 316 (0.000194)\n",
      "803. feature 198 (0.000194)\n",
      "804. feature 82 (0.000193)\n",
      "805. feature 1173 (0.000193)\n",
      "806. feature 97 (0.000193)\n",
      "807. feature 83 (0.000193)\n",
      "808. feature 255 (0.000192)\n",
      "809. feature 172 (0.000192)\n",
      "810. feature 1043 (0.000189)\n",
      "811. feature 1015 (0.000189)\n",
      "812. feature 91 (0.000189)\n",
      "813. feature 997 (0.000189)\n",
      "814. feature 847 (0.000189)\n",
      "815. feature 734 (0.000189)\n",
      "816. feature 145 (0.000188)\n",
      "817. feature 146 (0.000188)\n",
      "818. feature 604 (0.000188)\n",
      "819. feature 77 (0.000187)\n",
      "820. feature 27 (0.000187)\n",
      "821. feature 64 (0.000187)\n",
      "822. feature 70 (0.000187)\n",
      "823. feature 366 (0.000186)\n",
      "824. feature 1008 (0.000186)\n",
      "825. feature 592 (0.000186)\n",
      "826. feature 490 (0.000186)\n",
      "827. feature 774 (0.000186)\n",
      "828. feature 720 (0.000185)\n",
      "829. feature 1161 (0.000185)\n",
      "830. feature 782 (0.000185)\n",
      "831. feature 466 (0.000185)\n",
      "832. feature 360 (0.000184)\n",
      "833. feature 706 (0.000183)\n",
      "834. feature 132 (0.000183)\n",
      "835. feature 936 (0.000183)\n",
      "836. feature 10 (0.000183)\n",
      "837. feature 294 (0.000183)\n",
      "838. feature 722 (0.000182)\n",
      "839. feature 541 (0.000182)\n",
      "840. feature 50 (0.000182)\n",
      "841. feature 51 (0.000182)\n",
      "842. feature 464 (0.000181)\n",
      "843. feature 835 (0.000181)\n",
      "844. feature 465 (0.000181)\n",
      "845. feature 356 (0.000180)\n",
      "846. feature 1129 (0.000180)\n",
      "847. feature 234 (0.000180)\n",
      "848. feature 9 (0.000179)\n",
      "849. feature 238 (0.000179)\n",
      "850. feature 217 (0.000179)\n",
      "851. feature 158 (0.000179)\n",
      "852. feature 181 (0.000178)\n",
      "853. feature 829 (0.000177)\n",
      "854. feature 726 (0.000177)\n",
      "855. feature 104 (0.000177)\n",
      "856. feature 289 (0.000177)\n",
      "857. feature 153 (0.000177)\n",
      "858. feature 565 (0.000177)\n",
      "859. feature 1 (0.000176)\n",
      "860. feature 993 (0.000176)\n",
      "861. feature 261 (0.000176)\n",
      "862. feature 489 (0.000176)\n",
      "863. feature 17 (0.000176)\n",
      "864. feature 301 (0.000176)\n",
      "865. feature 1098 (0.000175)\n",
      "866. feature 278 (0.000175)\n",
      "867. feature 933 (0.000175)\n",
      "868. feature 854 (0.000175)\n",
      "869. feature 888 (0.000175)\n",
      "870. feature 559 (0.000175)\n",
      "871. feature 115 (0.000175)\n",
      "872. feature 1055 (0.000174)\n",
      "873. feature 308 (0.000174)\n",
      "874. feature 84 (0.000173)\n",
      "875. feature 156 (0.000173)\n",
      "876. feature 537 (0.000173)\n",
      "877. feature 286 (0.000173)\n",
      "878. feature 704 (0.000172)\n",
      "879. feature 915 (0.000172)\n",
      "880. feature 263 (0.000172)\n",
      "881. feature 118 (0.000171)\n",
      "882. feature 245 (0.000169)\n",
      "883. feature 67 (0.000169)\n",
      "884. feature 896 (0.000169)\n",
      "885. feature 522 (0.000168)\n",
      "886. feature 127 (0.000168)\n",
      "887. feature 47 (0.000168)\n",
      "888. feature 845 (0.000168)\n",
      "889. feature 165 (0.000167)\n",
      "890. feature 885 (0.000167)\n",
      "891. feature 772 (0.000167)\n",
      "892. feature 170 (0.000167)\n",
      "893. feature 1209 (0.000167)\n",
      "894. feature 314 (0.000167)\n",
      "895. feature 28 (0.000166)\n",
      "896. feature 405 (0.000166)\n",
      "897. feature 191 (0.000166)\n",
      "898. feature 126 (0.000165)\n",
      "899. feature 80 (0.000165)\n",
      "900. feature 60 (0.000164)\n",
      "901. feature 891 (0.000164)\n",
      "902. feature 281 (0.000163)\n",
      "903. feature 623 (0.000163)\n",
      "904. feature 859 (0.000162)\n",
      "905. feature 317 (0.000162)\n",
      "906. feature 510 (0.000162)\n",
      "907. feature 686 (0.000162)\n",
      "908. feature 242 (0.000161)\n",
      "909. feature 755 (0.000161)\n",
      "910. feature 291 (0.000161)\n",
      "911. feature 52 (0.000161)\n",
      "912. feature 139 (0.000161)\n",
      "913. feature 208 (0.000160)\n",
      "914. feature 939 (0.000160)\n",
      "915. feature 303 (0.000159)\n",
      "916. feature 148 (0.000159)\n",
      "917. feature 867 (0.000159)\n",
      "918. feature 740 (0.000159)\n",
      "919. feature 1058 (0.000159)\n",
      "920. feature 1068 (0.000158)\n",
      "921. feature 832 (0.000158)\n",
      "922. feature 754 (0.000157)\n",
      "923. feature 1180 (0.000157)\n",
      "924. feature 299 (0.000156)\n",
      "925. feature 861 (0.000156)\n",
      "926. feature 743 (0.000156)\n",
      "927. feature 93 (0.000155)\n",
      "928. feature 187 (0.000155)\n",
      "929. feature 113 (0.000155)\n",
      "930. feature 277 (0.000155)\n",
      "931. feature 280 (0.000154)\n",
      "932. feature 69 (0.000154)\n",
      "933. feature 460 (0.000154)\n",
      "934. feature 1185 (0.000154)\n",
      "935. feature 1183 (0.000154)\n",
      "936. feature 372 (0.000154)\n",
      "937. feature 375 (0.000153)\n",
      "938. feature 916 (0.000153)\n",
      "939. feature 925 (0.000153)\n",
      "940. feature 920 (0.000153)\n",
      "941. feature 694 (0.000153)\n",
      "942. feature 440 (0.000153)\n",
      "943. feature 448 (0.000152)\n",
      "944. feature 188 (0.000152)\n",
      "945. feature 293 (0.000151)\n",
      "946. feature 298 (0.000151)\n",
      "947. feature 367 (0.000151)\n",
      "948. feature 409 (0.000151)\n",
      "949. feature 1056 (0.000151)\n",
      "950. feature 1079 (0.000150)\n",
      "951. feature 1063 (0.000150)\n",
      "952. feature 533 (0.000150)\n",
      "953. feature 159 (0.000150)\n",
      "954. feature 232 (0.000149)\n",
      "955. feature 773 (0.000149)\n",
      "956. feature 241 (0.000149)\n",
      "957. feature 112 (0.000148)\n",
      "958. feature 105 (0.000148)\n",
      "959. feature 374 (0.000148)\n",
      "960. feature 459 (0.000147)\n",
      "961. feature 78 (0.000147)\n",
      "962. feature 304 (0.000146)\n",
      "963. feature 363 (0.000146)\n",
      "964. feature 94 (0.000146)\n",
      "965. feature 1157 (0.000145)\n",
      "966. feature 40 (0.000145)\n",
      "967. feature 259 (0.000145)\n",
      "968. feature 86 (0.000144)\n",
      "969. feature 155 (0.000144)\n",
      "970. feature 154 (0.000144)\n",
      "971. feature 330 (0.000143)\n",
      "972. feature 302 (0.000143)\n",
      "973. feature 171 (0.000143)\n",
      "974. feature 33 (0.000142)\n",
      "975. feature 1175 (0.000142)\n",
      "976. feature 365 (0.000141)\n",
      "977. feature 15 (0.000141)\n",
      "978. feature 167 (0.000141)\n",
      "979. feature 297 (0.000140)\n",
      "980. feature 1113 (0.000140)\n",
      "981. feature 691 (0.000139)\n",
      "982. feature 1192 (0.000138)\n",
      "983. feature 884 (0.000138)\n",
      "984. feature 479 (0.000138)\n",
      "985. feature 1054 (0.000138)\n",
      "986. feature 285 (0.000137)\n",
      "987. feature 701 (0.000137)\n",
      "988. feature 679 (0.000137)\n",
      "989. feature 322 (0.000137)\n",
      "990. feature 725 (0.000136)\n",
      "991. feature 125 (0.000136)\n",
      "992. feature 282 (0.000136)\n",
      "993. feature 1132 (0.000135)\n",
      "994. feature 758 (0.000135)\n",
      "995. feature 761 (0.000134)\n",
      "996. feature 763 (0.000134)\n",
      "997. feature 529 (0.000134)\n",
      "998. feature 228 (0.000133)\n",
      "999. feature 906 (0.000133)\n",
      "1000. feature 530 (0.000133)\n",
      "1001. feature 918 (0.000133)\n",
      "1002. feature 1049 (0.000133)\n",
      "1003. feature 744 (0.000133)\n",
      "1004. feature 721 (0.000133)\n",
      "1005. feature 350 (0.000133)\n",
      "1006. feature 500 (0.000132)\n",
      "1007. feature 919 (0.000132)\n",
      "1008. feature 110 (0.000132)\n",
      "1009. feature 327 (0.000131)\n",
      "1010. feature 334 (0.000131)\n",
      "1011. feature 930 (0.000131)\n",
      "1012. feature 223 (0.000131)\n",
      "1013. feature 454 (0.000130)\n",
      "1014. feature 771 (0.000129)\n",
      "1015. feature 108 (0.000129)\n",
      "1016. feature 287 (0.000129)\n",
      "1017. feature 1156 (0.000128)\n",
      "1018. feature 751 (0.000128)\n",
      "1019. feature 515 (0.000128)\n",
      "1020. feature 1154 (0.000127)\n",
      "1021. feature 1104 (0.000127)\n",
      "1022. feature 1004 (0.000127)\n",
      "1023. feature 560 (0.000126)\n",
      "1024. feature 689 (0.000126)\n",
      "1025. feature 79 (0.000125)\n",
      "1026. feature 732 (0.000125)\n",
      "1027. feature 111 (0.000125)\n",
      "1028. feature 683 (0.000124)\n",
      "1029. feature 1208 (0.000124)\n",
      "1030. feature 204 (0.000124)\n",
      "1031. feature 769 (0.000124)\n",
      "1032. feature 878 (0.000123)\n",
      "1033. feature 320 (0.000122)\n",
      "1034. feature 902 (0.000122)\n",
      "1035. feature 54 (0.000121)\n",
      "1036. feature 48 (0.000121)\n",
      "1037. feature 439 (0.000121)\n",
      "1038. feature 135 (0.000120)\n",
      "1039. feature 856 (0.000120)\n",
      "1040. feature 741 (0.000120)\n",
      "1041. feature 886 (0.000120)\n",
      "1042. feature 147 (0.000120)\n",
      "1043. feature 952 (0.000119)\n",
      "1044. feature 890 (0.000119)\n",
      "1045. feature 507 (0.000119)\n",
      "1046. feature 1111 (0.000119)\n",
      "1047. feature 1022 (0.000118)\n",
      "1048. feature 1134 (0.000118)\n",
      "1049. feature 121 (0.000118)\n",
      "1050. feature 144 (0.000118)\n",
      "1051. feature 682 (0.000117)\n",
      "1052. feature 136 (0.000117)\n",
      "1053. feature 284 (0.000117)\n",
      "1054. feature 516 (0.000116)\n",
      "1055. feature 457 (0.000116)\n",
      "1056. feature 501 (0.000115)\n",
      "1057. feature 718 (0.000115)\n",
      "1058. feature 149 (0.000115)\n",
      "1059. feature 68 (0.000114)\n",
      "1060. feature 472 (0.000113)\n",
      "1061. feature 676 (0.000113)\n",
      "1062. feature 733 (0.000113)\n",
      "1063. feature 858 (0.000112)\n",
      "1064. feature 150 (0.000112)\n",
      "1065. feature 168 (0.000112)\n",
      "1066. feature 95 (0.000112)\n",
      "1067. feature 143 (0.000111)\n",
      "1068. feature 527 (0.000111)\n",
      "1069. feature 932 (0.000110)\n",
      "1070. feature 114 (0.000109)\n",
      "1071. feature 292 (0.000109)\n",
      "1072. feature 1060 (0.000109)\n",
      "1073. feature 251 (0.000108)\n",
      "1074. feature 1099 (0.000108)\n",
      "1075. feature 898 (0.000108)\n",
      "1076. feature 89 (0.000107)\n",
      "1077. feature 173 (0.000107)\n",
      "1078. feature 134 (0.000107)\n",
      "1079. feature 1106 (0.000106)\n",
      "1080. feature 719 (0.000106)\n",
      "1081. feature 922 (0.000105)\n",
      "1082. feature 910 (0.000105)\n",
      "1083. feature 247 (0.000104)\n",
      "1084. feature 1143 (0.000104)\n",
      "1085. feature 452 (0.000104)\n",
      "1086. feature 133 (0.000104)\n",
      "1087. feature 502 (0.000103)\n",
      "1088. feature 1085 (0.000103)\n",
      "1089. feature 767 (0.000103)\n",
      "1090. feature 731 (0.000102)\n",
      "1091. feature 901 (0.000102)\n",
      "1092. feature 928 (0.000102)\n",
      "1093. feature 863 (0.000102)\n",
      "1094. feature 584 (0.000101)\n",
      "1095. feature 924 (0.000101)\n",
      "1096. feature 511 (0.000101)\n",
      "1097. feature 1084 (0.000101)\n",
      "1098. feature 151 (0.000101)\n",
      "1099. feature 477 (0.000101)\n",
      "1100. feature 1083 (0.000100)\n",
      "1101. feature 458 (0.000099)\n",
      "1102. feature 893 (0.000099)\n",
      "1103. feature 305 (0.000099)\n",
      "1104. feature 850 (0.000099)\n",
      "1105. feature 1059 (0.000098)\n",
      "1106. feature 182 (0.000098)\n",
      "1107. feature 1155 (0.000098)\n",
      "1108. feature 73 (0.000097)\n",
      "1109. feature 1081 (0.000096)\n",
      "1110. feature 486 (0.000096)\n",
      "1111. feature 923 (0.000096)\n",
      "1112. feature 895 (0.000096)\n",
      "1113. feature 557 (0.000095)\n",
      "1114. feature 1057 (0.000095)\n",
      "1115. feature 887 (0.000095)\n",
      "1116. feature 757 (0.000095)\n",
      "1117. feature 306 (0.000094)\n",
      "1118. feature 748 (0.000094)\n",
      "1119. feature 764 (0.000094)\n",
      "1120. feature 1108 (0.000092)\n",
      "1121. feature 138 (0.000092)\n",
      "1122. feature 562 (0.000092)\n",
      "1123. feature 724 (0.000091)\n",
      "1124. feature 1186 (0.000091)\n",
      "1125. feature 532 (0.000090)\n",
      "1126. feature 1181 (0.000090)\n",
      "1127. feature 483 (0.000090)\n",
      "1128. feature 481 (0.000089)\n",
      "1129. feature 130 (0.000089)\n",
      "1130. feature 1135 (0.000089)\n",
      "1131. feature 152 (0.000089)\n",
      "1132. feature 441 (0.000088)\n",
      "1133. feature 717 (0.000088)\n",
      "1134. feature 328 (0.000087)\n",
      "1135. feature 46 (0.000087)\n",
      "1136. feature 716 (0.000087)\n",
      "1137. feature 1160 (0.000087)\n",
      "1138. feature 904 (0.000086)\n",
      "1139. feature 913 (0.000086)\n",
      "1140. feature 577 (0.000086)\n",
      "1141. feature 433 (0.000084)\n",
      "1142. feature 461 (0.000084)\n",
      "1143. feature 295 (0.000084)\n",
      "1144. feature 1062 (0.000083)\n",
      "1145. feature 1107 (0.000082)\n",
      "1146. feature 868 (0.000081)\n",
      "1147. feature 735 (0.000080)\n",
      "1148. feature 883 (0.000080)\n",
      "1149. feature 163 (0.000080)\n",
      "1150. feature 485 (0.000079)\n",
      "1151. feature 892 (0.000079)\n",
      "1152. feature 1061 (0.000078)\n",
      "1153. feature 927 (0.000078)\n",
      "1154. feature 882 (0.000078)\n",
      "1155. feature 1159 (0.000078)\n",
      "1156. feature 889 (0.000077)\n",
      "1157. feature 455 (0.000076)\n",
      "1158. feature 311 (0.000076)\n",
      "1159. feature 123 (0.000076)\n",
      "1160. feature 1086 (0.000075)\n",
      "1161. feature 1082 (0.000073)\n",
      "1162. feature 1179 (0.000073)\n",
      "1163. feature 528 (0.000073)\n",
      "1164. feature 361 (0.000073)\n",
      "1165. feature 765 (0.000073)\n",
      "1166. feature 929 (0.000072)\n",
      "1167. feature 1109 (0.000071)\n",
      "1168. feature 738 (0.000071)\n",
      "1169. feature 124 (0.000070)\n",
      "1170. feature 583 (0.000070)\n",
      "1171. feature 131 (0.000070)\n",
      "1172. feature 369 (0.000070)\n",
      "1173. feature 552 (0.000069)\n",
      "1174. feature 554 (0.000068)\n",
      "1175. feature 313 (0.000067)\n",
      "1176. feature 1080 (0.000066)\n",
      "1177. feature 736 (0.000066)\n",
      "1178. feature 482 (0.000065)\n",
      "1179. feature 1105 (0.000065)\n",
      "1180. feature 244 (0.000064)\n",
      "1181. feature 921 (0.000063)\n",
      "1182. feature 1182 (0.000063)\n",
      "1183. feature 478 (0.000062)\n",
      "1184. feature 1088 (0.000061)\n",
      "1185. feature 905 (0.000060)\n",
      "1186. feature 300 (0.000060)\n",
      "1187. feature 505 (0.000059)\n",
      "1188. feature 508 (0.000058)\n",
      "1189. feature 312 (0.000057)\n",
      "1190. feature 169 (0.000056)\n",
      "1191. feature 140 (0.000056)\n",
      "1192. feature 578 (0.000056)\n",
      "1193. feature 1130 (0.000054)\n",
      "1194. feature 480 (0.000054)\n",
      "1195. feature 1112 (0.000052)\n",
      "1196. feature 739 (0.000052)\n",
      "1197. feature 117 (0.000051)\n",
      "1198. feature 503 (0.000051)\n",
      "1199. feature 310 (0.000050)\n",
      "1200. feature 288 (0.000050)\n",
      "1201. feature 553 (0.000049)\n",
      "1202. feature 864 (0.000048)\n",
      "1203. feature 1184 (0.000048)\n",
      "1204. feature 315 (0.000047)\n",
      "1205. feature 129 (0.000045)\n",
      "1206. feature 509 (0.000045)\n",
      "1207. feature 1110 (0.000043)\n",
      "1208. feature 506 (0.000037)\n",
      "1209. feature 582 (0.000034)\n",
      "1210. feature 1131 (0.000033)\n",
      "1211. feature 504 (0.000031)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe722f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# features analysis\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "X = data_train[features]\n",
    "Y = data_train['label']\n",
    "\n",
    "forest.fit(X, Y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature 388 (1.000000)\n",
      "2. feature 988 (0.977711)\n",
      "3. feature 990 (0.900733)\n",
      "4. feature 956 (0.771606)\n",
      "5. feature 386 (0.742600)\n",
      "6. feature 989 (0.738875)\n",
      "7. feature 1045 (0.698334)\n",
      "8. feature 1071 (0.671445)\n",
      "9. feature 1121 (0.647973)\n",
      "10. feature 387 (0.642872)\n",
      "11. feature 609 (0.535209)\n",
      "12. feature 1011 (0.515246)\n",
      "13. feature 1120 (0.470980)\n",
      "14. feature 965 (0.455276)\n",
      "15. feature 966 (0.441449)\n",
      "16. feature 183 (0.439641)\n",
      "17. feature 1144 (0.436431)\n",
      "18. feature 1146 (0.431465)\n",
      "19. feature 1010 (0.392307)\n",
      "20. feature 955 (0.376049)\n",
      "21. feature 1171 (0.367005)\n",
      "22. feature 1046 (0.363573)\n",
      "23. feature 1119 (0.348404)\n",
      "24. feature 1070 (0.326618)\n",
      "25. feature 985 (0.326367)\n",
      "26. feature 787 (0.325820)\n",
      "27. feature 184 (0.322909)\n",
      "28. feature 1190 (0.315951)\n",
      "29. feature 946 (0.313070)\n",
      "30. feature 945 (0.311466)\n",
      "31. feature 625 (0.288289)\n",
      "32. feature 599 (0.283205)\n",
      "33. feature 1203 (0.275502)\n",
      "34. feature 786 (0.274288)\n",
      "35. feature 1145 (0.269851)\n",
      "36. feature 627 (0.259795)\n",
      "37. feature 1196 (0.229907)\n",
      "38. feature 971 (0.229471)\n",
      "39. feature 1191 (0.229204)\n",
      "40. feature 1201 (0.223834)\n",
      "41. feature 964 (0.222412)\n",
      "42. feature 957 (0.214817)\n",
      "43. feature 1095 (0.213715)\n",
      "44. feature 944 (0.213422)\n",
      "45. feature 785 (0.209098)\n",
      "46. feature 1009 (0.208125)\n",
      "47. feature 492 (0.204614)\n",
      "48. feature 970 (0.204508)\n",
      "49. feature 1169 (0.204058)\n",
      "50. feature 1193 (0.195755)\n",
      "51. feature 343 (0.195566)\n",
      "52. feature 789 (0.193906)\n",
      "53. feature 517 (0.193640)\n",
      "54. feature 1031 (0.191329)\n",
      "55. feature 569 (0.189956)\n",
      "56. feature 940 (0.186949)\n",
      "57. feature 1170 (0.186620)\n",
      "58. feature 996 (0.186054)\n",
      "59. feature 1094 (0.183038)\n",
      "60. feature 573 (0.180327)\n",
      "61. feature 1012 (0.176257)\n",
      "62. feature 519 (0.176134)\n",
      "63. feature 1018 (0.175681)\n",
      "64. feature 979 (0.173901)\n",
      "65. feature 986 (0.171150)\n",
      "66. feature 601 (0.166847)\n",
      "67. feature 987 (0.166271)\n",
      "68. feature 494 (0.165480)\n",
      "69. feature 608 (0.160871)\n",
      "70. feature 1122 (0.158661)\n",
      "71. feature 1030 (0.157936)\n",
      "72. feature 1044 (0.157057)\n",
      "73. feature 943 (0.154316)\n",
      "74. feature 779 (0.153462)\n",
      "75. feature 972 (0.153183)\n",
      "76. feature 1047 (0.152121)\n",
      "77. feature 1069 (0.150178)\n",
      "78. feature 610 (0.148009)\n",
      "79. feature 1032 (0.146918)\n",
      "80. feature 442 (0.143706)\n",
      "81. feature 954 (0.143051)\n",
      "82. feature 589 (0.141904)\n",
      "83. feature 941 (0.140116)\n",
      "84. feature 185 (0.138772)\n",
      "85. feature 341 (0.137605)\n",
      "86. feature 967 (0.136976)\n",
      "87. feature 549 (0.136712)\n",
      "88. feature 968 (0.136273)\n",
      "89. feature 949 (0.130187)\n",
      "90. feature 636 (0.128719)\n",
      "91. feature 383 (0.126016)\n",
      "92. feature 1001 (0.125854)\n",
      "93. feature 1097 (0.124800)\n",
      "94. feature 654 (0.123483)\n",
      "95. feature 574 (0.122993)\n",
      "96. feature 788 (0.122915)\n",
      "97. feature 524 (0.122337)\n",
      "98. feature 1096 (0.121534)\n",
      "99. feature 568 (0.121384)\n",
      "100. feature 1072 (0.120767)\n",
      "101. feature 526 (0.119476)\n",
      "102. feature 1014 (0.117743)\n",
      "103. feature 1147 (0.116443)\n",
      "104. feature 1000 (0.115442)\n",
      "105. feature 1200 (0.115169)\n",
      "106. feature 444 (0.113497)\n",
      "107. feature 591 (0.113129)\n",
      "108. feature 468 (0.112973)\n",
      "109. feature 543 (0.112503)\n",
      "110. feature 626 (0.112281)\n",
      "111. feature 994 (0.109538)\n",
      "112. feature 1013 (0.108876)\n",
      "113. feature 338 (0.108284)\n",
      "114. feature 1026 (0.107779)\n",
      "115. feature 23 (0.107451)\n",
      "116. feature 571 (0.107090)\n",
      "117. feature 1035 (0.105871)\n",
      "118. feature 544 (0.105101)\n",
      "119. feature 1195 (0.104798)\n",
      "120. feature 1204 (0.103536)\n",
      "121. feature 422 (0.103063)\n",
      "122. feature 1065 (0.103060)\n",
      "123. feature 520 (0.101049)\n",
      "124. feature 495 (0.098578)\n",
      "125. feature 1019 (0.096608)\n",
      "126. feature 798 (0.096072)\n",
      "127. feature 1066 (0.095266)\n",
      "128. feature 1139 (0.094434)\n",
      "129. feature 803 (0.094060)\n",
      "130. feature 641 (0.092948)\n",
      "131. feature 428 (0.092642)\n",
      "132. feature 575 (0.091540)\n",
      "133. feature 498 (0.091092)\n",
      "134. feature 570 (0.090174)\n",
      "135. feature 1033 (0.089191)\n",
      "136. feature 760 (0.089065)\n",
      "137. feature 1002 (0.088875)\n",
      "138. feature 801 (0.088636)\n",
      "139. feature 493 (0.087393)\n",
      "140. feature 423 (0.086829)\n",
      "141. feature 780 (0.086559)\n",
      "142. feature 1172 (0.086066)\n",
      "143. feature 594 (0.086035)\n",
      "144. feature 443 (0.085419)\n",
      "145. feature 1040 (0.085349)\n",
      "146. feature 827 (0.085275)\n",
      "147. feature 1028 (0.085084)\n",
      "148. feature 1126 (0.084248)\n",
      "149. feature 550 (0.084151)\n",
      "150. feature 976 (0.084123)\n",
      "151. feature 980 (0.083908)\n",
      "152. feature 1128 (0.083177)\n",
      "153. feature 995 (0.083037)\n",
      "154. feature 518 (0.082161)\n",
      "155. feature 810 (0.081387)\n",
      "156. feature 948 (0.080542)\n",
      "157. feature 445 (0.080273)\n",
      "158. feature 1020 (0.079866)\n",
      "159. feature 828 (0.079739)\n",
      "160. feature 429 (0.079487)\n",
      "161. feature 951 (0.079312)\n",
      "162. feature 384 (0.078836)\n",
      "163. feature 714 (0.078461)\n",
      "164. feature 1024 (0.078457)\n",
      "165. feature 469 (0.078451)\n",
      "166. feature 603 (0.078424)\n",
      "167. feature 1141 (0.078360)\n",
      "168. feature 628 (0.077088)\n",
      "169. feature 340 (0.076695)\n",
      "170. feature 645 (0.076549)\n",
      "171. feature 1048 (0.076292)\n",
      "172. feature 792 (0.075739)\n",
      "173. feature 978 (0.075321)\n",
      "174. feature 567 (0.074813)\n",
      "175. feature 1198 (0.074231)\n",
      "176. feature 467 (0.073909)\n",
      "177. feature 759 (0.073893)\n",
      "178. feature 815 (0.073552)\n",
      "179. feature 806 (0.073502)\n",
      "180. feature 638 (0.072895)\n",
      "181. feature 545 (0.072167)\n",
      "182. feature 804 (0.072101)\n",
      "183. feature 969 (0.072035)\n",
      "184. feature 1038 (0.070903)\n",
      "185. feature 650 (0.070805)\n",
      "186. feature 1116 (0.070008)\n",
      "187. feature 1053 (0.069847)\n",
      "188. feature 1153 (0.069757)\n",
      "189. feature 656 (0.069239)\n",
      "190. feature 647 (0.068786)\n",
      "191. feature 1025 (0.068666)\n",
      "192. feature 1148 (0.068403)\n",
      "193. feature 1123 (0.068105)\n",
      "194. feature 1034 (0.067636)\n",
      "195. feature 745 (0.067576)\n",
      "196. feature 633 (0.067182)\n",
      "197. feature 424 (0.066718)\n",
      "198. feature 474 (0.066651)\n",
      "199. feature 408 (0.066566)\n",
      "200. feature 598 (0.065276)\n",
      "201. feature 1115 (0.064859)\n",
      "202. feature 398 (0.064440)\n",
      "203. feature 352 (0.063565)\n",
      "204. feature 991 (0.063259)\n",
      "205. feature 639 (0.063129)\n",
      "206. feature 818 (0.062475)\n",
      "207. feature 521 (0.062435)\n",
      "208. feature 354 (0.060873)\n",
      "209. feature 800 (0.060652)\n",
      "210. feature 646 (0.059870)\n",
      "211. feature 1142 (0.059598)\n",
      "212. feature 380 (0.059498)\n",
      "213. feature 699 (0.058109)\n",
      "214. feature 657 (0.057926)\n",
      "215. feature 1140 (0.057107)\n",
      "216. feature 973 (0.056867)\n",
      "217. feature 342 (0.056849)\n",
      "218. feature 648 (0.056591)\n",
      "219. feature 619 (0.056269)\n",
      "220. feature 345 (0.055768)\n",
      "221. feature 546 (0.055622)\n",
      "222. feature 430 (0.055515)\n",
      "223. feature 825 (0.055271)\n",
      "224. feature 630 (0.055158)\n",
      "225. feature 1194 (0.054964)\n",
      "226. feature 790 (0.054735)\n",
      "227. feature 1036 (0.054511)\n",
      "228. feature 819 (0.054469)\n",
      "229. feature 1152 (0.053910)\n",
      "230. feature 793 (0.053776)\n",
      "231. feature 347 (0.053673)\n",
      "232. feature 698 (0.053326)\n",
      "233. feature 1073 (0.053276)\n",
      "234. feature 947 (0.052912)\n",
      "235. feature 795 (0.052833)\n",
      "236. feature 962 (0.052708)\n",
      "237. feature 665 (0.052296)\n",
      "238. feature 576 (0.052149)\n",
      "239. feature 1189 (0.052047)\n",
      "240. feature 1076 (0.051657)\n",
      "241. feature 177 (0.051361)\n",
      "242. feature 662 (0.050927)\n",
      "243. feature 600 (0.050802)\n",
      "244. feature 836 (0.050019)\n",
      "245. feature 821 (0.050004)\n",
      "246. feature 1075 (0.049938)\n",
      "247. feature 672 (0.049718)\n",
      "248. feature 497 (0.049188)\n",
      "249. feature 353 (0.048963)\n",
      "250. feature 385 (0.048718)\n",
      "251. feature 523 (0.048296)\n",
      "252. feature 977 (0.048120)\n",
      "253. feature 103 (0.047990)\n",
      "254. feature 663 (0.047900)\n",
      "255. feature 339 (0.046962)\n",
      "256. feature 842 (0.046885)\n",
      "257. feature 668 (0.046692)\n",
      "258. feature 1127 (0.046028)\n",
      "259. feature 816 (0.045372)\n",
      "260. feature 417 (0.044481)\n",
      "261. feature 837 (0.044430)\n",
      "262. feature 355 (0.044259)\n",
      "263. feature 1027 (0.043729)\n",
      "264. feature 1151 (0.043579)\n",
      "265. feature 807 (0.043565)\n",
      "266. feature 1051 (0.043314)\n",
      "267. feature 1089 (0.043182)\n",
      "268. feature 411 (0.043155)\n",
      "269. feature 1078 (0.043069)\n",
      "270. feature 1052 (0.042990)\n",
      "271. feature 13 (0.042910)\n",
      "272. feature 822 (0.042905)\n",
      "273. feature 982 (0.042859)\n",
      "274. feature 436 (0.042800)\n",
      "275. feature 6 (0.042435)\n",
      "276. feature 909 (0.042007)\n",
      "277. feature 1125 (0.041655)\n",
      "278. feature 418 (0.041433)\n",
      "279. feature 831 (0.041049)\n",
      "280. feature 269 (0.040769)\n",
      "281. feature 346 (0.040632)\n",
      "282. feature 983 (0.040591)\n",
      "283. feature 942 (0.040404)\n",
      "284. feature 585 (0.040124)\n",
      "285. feature 631 (0.040044)\n",
      "286. feature 425 (0.039870)\n",
      "287. feature 531 (0.039619)\n",
      "288. feature 642 (0.039470)\n",
      "289. feature 635 (0.039310)\n",
      "290. feature 813 (0.038540)\n",
      "291. feature 781 (0.038308)\n",
      "292. feature 542 (0.038045)\n",
      "293. feature 1163 (0.038002)\n",
      "294. feature 791 (0.037963)\n",
      "295. feature 1042 (0.037855)\n",
      "296. feature 412 (0.037826)\n",
      "297. feature 1041 (0.037744)\n",
      "298. feature 938 (0.037520)\n",
      "299. feature 1150 (0.037476)\n",
      "300. feature 661 (0.037056)\n",
      "301. feature 809 (0.036845)\n",
      "302. feature 653 (0.036776)\n",
      "303. feature 830 (0.036744)\n",
      "304. feature 671 (0.036713)\n",
      "305. feature 618 (0.036679)\n",
      "306. feature 12 (0.036642)\n",
      "307. feature 824 (0.036231)\n",
      "308. feature 632 (0.035883)\n",
      "309. feature 1064 (0.035685)\n",
      "310. feature 45 (0.035605)\n",
      "311. feature 393 (0.035267)\n",
      "312. feature 268 (0.035168)\n",
      "313. feature 693 (0.034960)\n",
      "314. feature 239 (0.034932)\n",
      "315. feature 221 (0.034319)\n",
      "316. feature 593 (0.033910)\n",
      "317. feature 643 (0.033865)\n",
      "318. feature 1037 (0.033704)\n",
      "319. feature 783 (0.033690)\n",
      "320. feature 240 (0.033489)\n",
      "321. feature 21 (0.033455)\n",
      "322. feature 834 (0.033076)\n",
      "323. feature 799 (0.032944)\n",
      "324. feature 812 (0.032938)\n",
      "325. feature 1101 (0.032860)\n",
      "326. feature 1174 (0.032702)\n",
      "327. feature 833 (0.032462)\n",
      "328. feature 677 (0.032330)\n",
      "329. feature 432 (0.032169)\n",
      "330. feature 660 (0.032098)\n",
      "331. feature 534 (0.032070)\n",
      "332. feature 496 (0.031991)\n",
      "333. feature 175 (0.031897)\n",
      "334. feature 38 (0.031708)\n",
      "335. feature 499 (0.031515)\n",
      "336. feature 1114 (0.031243)\n",
      "337. feature 349 (0.031215)\n",
      "338. feature 189 (0.031209)\n",
      "339. feature 100 (0.031087)\n",
      "340. feature 106 (0.031061)\n",
      "341. feature 265 (0.030945)\n",
      "342. feature 337 (0.030943)\n",
      "343. feature 596 (0.030734)\n",
      "344. feature 644 (0.030687)\n",
      "345. feature 1100 (0.030618)\n",
      "346. feature 666 (0.030607)\n",
      "347. feature 950 (0.030607)\n",
      "348. feature 19 (0.030473)\n",
      "349. feature 400 (0.030399)\n",
      "350. feature 588 (0.030372)\n",
      "351. feature 186 (0.030264)\n",
      "352. feature 449 (0.030252)\n",
      "353. feature 640 (0.030177)\n",
      "354. feature 420 (0.030069)\n",
      "355. feature 687 (0.029905)\n",
      "356. feature 1177 (0.029827)\n",
      "357. feature 275 (0.029624)\n",
      "358. feature 271 (0.029248)\n",
      "359. feature 669 (0.029198)\n",
      "360. feature 1029 (0.029187)\n",
      "361. feature 394 (0.028981)\n",
      "362. feature 651 (0.028791)\n",
      "363. feature 237 (0.028761)\n",
      "364. feature 851 (0.028689)\n",
      "365. feature 875 (0.028513)\n",
      "366. feature 229 (0.028447)\n",
      "367. feature 655 (0.028285)\n",
      "368. feature 264 (0.028264)\n",
      "369. feature 437 (0.028237)\n",
      "370. feature 41 (0.028187)\n",
      "371. feature 877 (0.027854)\n",
      "372. feature 606 (0.027822)\n",
      "373. feature 1090 (0.027779)\n",
      "374. feature 848 (0.027326)\n",
      "375. feature 602 (0.027318)\n",
      "376. feature 381 (0.027276)\n",
      "377. feature 525 (0.027088)\n",
      "378. feature 595 (0.026981)\n",
      "379. feature 536 (0.026974)\n",
      "380. feature 473 (0.026879)\n",
      "381. feature 1102 (0.026841)\n",
      "382. feature 1067 (0.026713)\n",
      "383. feature 1124 (0.026666)\n",
      "384. feature 587 (0.026314)\n",
      "385. feature 1205 (0.026237)\n",
      "386. feature 777 (0.026124)\n",
      "387. feature 1166 (0.026116)\n",
      "388. feature 684 (0.025899)\n",
      "389. feature 539 (0.025866)\n",
      "390. feature 344 (0.025742)\n",
      "391. feature 796 (0.025733)\n",
      "392. feature 61 (0.025728)\n",
      "393. feature 974 (0.025675)\n",
      "394. feature 11 (0.025470)\n",
      "395. feature 963 (0.025437)\n",
      "396. feature 218 (0.025344)\n",
      "397. feature 649 (0.025276)\n",
      "398. feature 416 (0.025015)\n",
      "399. feature 659 (0.025014)\n",
      "400. feature 561 (0.024907)\n",
      "401. feature 664 (0.024860)\n",
      "402. feature 1050 (0.024801)\n",
      "403. feature 1117 (0.024725)\n",
      "404. feature 404 (0.024593)\n",
      "405. feature 246 (0.024589)\n",
      "406. feature 855 (0.024576)\n",
      "407. feature 272 (0.024514)\n",
      "408. feature 471 (0.024273)\n",
      "409. feature 206 (0.024258)\n",
      "410. feature 101 (0.024214)\n",
      "411. feature 1176 (0.024010)\n",
      "412. feature 840 (0.023965)\n",
      "413. feature 857 (0.023924)\n",
      "414. feature 696 (0.023887)\n",
      "415. feature 820 (0.023876)\n",
      "416. feature 805 (0.023801)\n",
      "417. feature 475 (0.023799)\n",
      "418. feature 431 (0.023720)\n",
      "419. feature 535 (0.023687)\n",
      "420. feature 776 (0.023676)\n",
      "421. feature 975 (0.023670)\n",
      "422. feature 612 (0.023506)\n",
      "423. feature 249 (0.023476)\n",
      "424. feature 981 (0.023435)\n",
      "425. feature 695 (0.023389)\n",
      "426. feature 917 (0.023263)\n",
      "427. feature 348 (0.023257)\n",
      "428. feature 74 (0.023106)\n",
      "429. feature 849 (0.023068)\n",
      "430. feature 1149 (0.022732)\n",
      "431. feature 1003 (0.022727)\n",
      "432. feature 243 (0.022646)\n",
      "433. feature 620 (0.022617)\n",
      "434. feature 236 (0.022587)\n",
      "435. feature 7 (0.022575)\n",
      "436. feature 1199 (0.022520)\n",
      "437. feature 1077 (0.022285)\n",
      "438. feature 778 (0.022224)\n",
      "439. feature 826 (0.022190)\n",
      "440. feature 1091 (0.022099)\n",
      "441. feature 378 (0.022038)\n",
      "442. feature 63 (0.022028)\n",
      "443. feature 395 (0.022019)\n",
      "444. feature 551 (0.021990)\n",
      "445. feature 961 (0.021957)\n",
      "446. feature 102 (0.021928)\n",
      "447. feature 37 (0.021823)\n",
      "448. feature 540 (0.021795)\n",
      "449. feature 670 (0.021738)\n",
      "450. feature 207 (0.021723)\n",
      "451. feature 839 (0.021619)\n",
      "452. feature 894 (0.021592)\n",
      "453. feature 658 (0.021527)\n",
      "454. feature 998 (0.021488)\n",
      "455. feature 808 (0.021275)\n",
      "456. feature 463 (0.021157)\n",
      "457. feature 20 (0.021157)\n",
      "458. feature 1092 (0.020969)\n",
      "459. feature 1197 (0.020838)\n",
      "460. feature 274 (0.020803)\n",
      "461. feature 195 (0.020786)\n",
      "462. feature 911 (0.020639)\n",
      "463. feature 87 (0.020439)\n",
      "464. feature 853 (0.020383)\n",
      "465. feature 137 (0.020327)\n",
      "466. feature 1103 (0.020308)\n",
      "467. feature 1005 (0.020210)\n",
      "468. feature 34 (0.020153)\n",
      "469. feature 634 (0.020138)\n",
      "470. feature 811 (0.020128)\n",
      "471. feature 72 (0.019910)\n",
      "472. feature 359 (0.019864)\n",
      "473. feature 382 (0.019850)\n",
      "474. feature 226 (0.019618)\n",
      "475. feature 616 (0.019580)\n",
      "476. feature 446 (0.019546)\n",
      "477. feature 675 (0.019541)\n",
      "478. feature 18 (0.019532)\n",
      "479. feature 814 (0.019455)\n",
      "480. feature 817 (0.019404)\n",
      "481. feature 1137 (0.019335)\n",
      "482. feature 202 (0.019332)\n",
      "483. feature 215 (0.019322)\n",
      "484. feature 566 (0.019307)\n",
      "485. feature 908 (0.019304)\n",
      "486. feature 555 (0.019236)\n",
      "487. feature 615 (0.019095)\n",
      "488. feature 992 (0.019038)\n",
      "489. feature 712 (0.018985)\n",
      "490. feature 227 (0.018982)\n",
      "491. feature 90 (0.018937)\n",
      "492. feature 267 (0.018861)\n",
      "493. feature 470 (0.018846)\n",
      "494. feature 1039 (0.018831)\n",
      "495. feature 414 (0.018816)\n",
      "496. feature 8 (0.018792)\n",
      "497. feature 225 (0.018776)\n",
      "498. feature 53 (0.018735)\n",
      "499. feature 403 (0.018713)\n",
      "500. feature 81 (0.018708)\n",
      "501. feature 749 (0.018668)\n",
      "502. feature 26 (0.018622)\n",
      "503. feature 586 (0.018615)\n",
      "504. feature 958 (0.018600)\n",
      "505. feature 1016 (0.018563)\n",
      "506. feature 266 (0.018530)\n",
      "507. feature 711 (0.018500)\n",
      "508. feature 415 (0.018453)\n",
      "509. feature 358 (0.018415)\n",
      "510. feature 296 (0.018393)\n",
      "511. feature 881 (0.018374)\n",
      "512. feature 203 (0.018279)\n",
      "513. feature 42 (0.018165)\n",
      "514. feature 488 (0.018116)\n",
      "515. feature 1017 (0.017914)\n",
      "516. feature 262 (0.017910)\n",
      "517. feature 512 (0.017909)\n",
      "518. feature 1164 (0.017904)\n",
      "519. feature 1021 (0.017888)\n",
      "520. feature 652 (0.017843)\n",
      "521. feature 462 (0.017820)\n",
      "522. feature 392 (0.017805)\n",
      "523. feature 866 (0.017755)\n",
      "524. feature 399 (0.017717)\n",
      "525. feature 624 (0.017702)\n",
      "526. feature 590 (0.017698)\n",
      "527. feature 873 (0.017634)\n",
      "528. feature 438 (0.017620)\n",
      "529. feature 637 (0.017592)\n",
      "530. feature 3 (0.017540)\n",
      "531. feature 621 (0.017525)\n",
      "532. feature 5 (0.017486)\n",
      "533. feature 190 (0.017431)\n",
      "534. feature 250 (0.017344)\n",
      "535. feature 213 (0.017317)\n",
      "536. feature 746 (0.017290)\n",
      "537. feature 410 (0.017290)\n",
      "538. feature 912 (0.017261)\n",
      "539. feature 2 (0.017217)\n",
      "540. feature 487 (0.017119)\n",
      "541. feature 32 (0.017082)\n",
      "542. feature 230 (0.017054)\n",
      "543. feature 270 (0.017045)\n",
      "544. feature 775 (0.017042)\n",
      "545. feature 937 (0.016986)\n",
      "546. feature 674 (0.016966)\n",
      "547. feature 219 (0.016921)\n",
      "548. feature 1138 (0.016906)\n",
      "549. feature 959 (0.016894)\n",
      "550. feature 426 (0.016883)\n",
      "551. feature 703 (0.016774)\n",
      "552. feature 1136 (0.016764)\n",
      "553. feature 179 (0.016752)\n",
      "554. feature 224 (0.016720)\n",
      "555. feature 1178 (0.016698)\n",
      "556. feature 252 (0.016685)\n",
      "557. feature 874 (0.016675)\n",
      "558. feature 96 (0.016660)\n",
      "559. feature 210 (0.016623)\n",
      "560. feature 514 (0.016600)\n",
      "561. feature 371 (0.016497)\n",
      "562. feature 597 (0.016446)\n",
      "563. feature 58 (0.016312)\n",
      "564. feature 377 (0.016210)\n",
      "565. feature 333 (0.016180)\n",
      "566. feature 157 (0.016165)\n",
      "567. feature 233 (0.016156)\n",
      "568. feature 1167 (0.016149)\n",
      "569. feature 376 (0.016129)\n",
      "570. feature 326 (0.016118)\n",
      "571. feature 667 (0.016116)\n",
      "572. feature 283 (0.016006)\n",
      "573. feature 953 (0.015962)\n",
      "574. feature 435 (0.015940)\n",
      "575. feature 581 (0.015925)\n",
      "576. feature 273 (0.015911)\n",
      "577. feature 180 (0.015902)\n",
      "578. feature 629 (0.015894)\n",
      "579. feature 747 (0.015843)\n",
      "580. feature 768 (0.015813)\n",
      "581. feature 205 (0.015761)\n",
      "582. feature 254 (0.015752)\n",
      "583. feature 681 (0.015731)\n",
      "584. feature 160 (0.015691)\n",
      "585. feature 29 (0.015672)\n",
      "586. feature 324 (0.015640)\n",
      "587. feature 209 (0.015567)\n",
      "588. feature 673 (0.015559)\n",
      "589. feature 49 (0.015483)\n",
      "590. feature 396 (0.015471)\n",
      "591. feature 710 (0.015421)\n",
      "592. feature 513 (0.015385)\n",
      "593. feature 914 (0.015363)\n",
      "594. feature 174 (0.015322)\n",
      "595. feature 357 (0.015309)\n",
      "596. feature 484 (0.015247)\n",
      "597. feature 25 (0.015223)\n",
      "598. feature 846 (0.015167)\n",
      "599. feature 934 (0.015153)\n",
      "600. feature 447 (0.015145)\n",
      "601. feature 201 (0.015102)\n",
      "602. feature 729 (0.015097)\n",
      "603. feature 22 (0.014999)\n",
      "604. feature 1006 (0.014926)\n",
      "605. feature 214 (0.014911)\n",
      "606. feature 162 (0.014864)\n",
      "607. feature 14 (0.014825)\n",
      "608. feature 730 (0.014815)\n",
      "609. feature 899 (0.014762)\n",
      "610. feature 1187 (0.014747)\n",
      "611. feature 351 (0.014737)\n",
      "612. feature 614 (0.014671)\n",
      "613. feature 199 (0.014654)\n",
      "614. feature 196 (0.014653)\n",
      "615. feature 931 (0.014561)\n",
      "616. feature 984 (0.014528)\n",
      "617. feature 66 (0.014511)\n",
      "618. feature 876 (0.014455)\n",
      "619. feature 336 (0.014412)\n",
      "620. feature 75 (0.014360)\n",
      "621. feature 235 (0.014344)\n",
      "622. feature 563 (0.014334)\n",
      "623. feature 784 (0.014321)\n",
      "624. feature 538 (0.014261)\n",
      "625. feature 897 (0.014251)\n",
      "626. feature 216 (0.014229)\n",
      "627. feature 1023 (0.014222)\n",
      "628. feature 59 (0.014215)\n",
      "629. feature 960 (0.014174)\n",
      "630. feature 690 (0.014167)\n",
      "631. feature 547 (0.014158)\n",
      "632. feature 56 (0.014132)\n",
      "633. feature 332 (0.014084)\n",
      "634. feature 390 (0.014073)\n",
      "635. feature 843 (0.014072)\n",
      "636. feature 419 (0.014067)\n",
      "637. feature 1162 (0.014053)\n",
      "638. feature 176 (0.014046)\n",
      "639. feature 1165 (0.013988)\n",
      "640. feature 852 (0.013940)\n",
      "641. feature 860 (0.013913)\n",
      "642. feature 200 (0.013898)\n",
      "643. feature 36 (0.013875)\n",
      "644. feature 685 (0.013874)\n",
      "645. feature 999 (0.013869)\n",
      "646. feature 413 (0.013807)\n",
      "647. feature 841 (0.013779)\n",
      "648. feature 1168 (0.013762)\n",
      "649. feature 723 (0.013756)\n",
      "650. feature 373 (0.013750)\n",
      "651. feature 76 (0.013728)\n",
      "652. feature 427 (0.013688)\n",
      "653. feature 607 (0.013633)\n",
      "654. feature 1202 (0.013633)\n",
      "655. feature 797 (0.013609)\n",
      "656. feature 368 (0.013596)\n",
      "657. feature 109 (0.013569)\n",
      "658. feature 476 (0.013555)\n",
      "659. feature 709 (0.013510)\n",
      "660. feature 678 (0.013381)\n",
      "661. feature 197 (0.013333)\n",
      "662. feature 98 (0.013296)\n",
      "663. feature 329 (0.013276)\n",
      "664. feature 752 (0.013267)\n",
      "665. feature 192 (0.013265)\n",
      "666. feature 24 (0.013263)\n",
      "667. feature 705 (0.013262)\n",
      "668. feature 548 (0.013250)\n",
      "669. feature 935 (0.013212)\n",
      "670. feature 756 (0.013208)\n",
      "671. feature 220 (0.013199)\n",
      "672. feature 1093 (0.013191)\n",
      "673. feature 688 (0.013189)\n",
      "674. feature 57 (0.013187)\n",
      "675. feature 178 (0.013182)\n",
      "676. feature 325 (0.013159)\n",
      "677. feature 164 (0.013119)\n",
      "678. feature 194 (0.013106)\n",
      "679. feature 193 (0.013103)\n",
      "680. feature 1007 (0.013088)\n",
      "681. feature 260 (0.013057)\n",
      "682. feature 1087 (0.013039)\n",
      "683. feature 556 (0.013027)\n",
      "684. feature 1118 (0.013010)\n",
      "685. feature 680 (0.013000)\n",
      "686. feature 450 (0.012996)\n",
      "687. feature 318 (0.012976)\n",
      "688. feature 4 (0.012934)\n",
      "689. feature 838 (0.012931)\n",
      "690. feature 116 (0.012903)\n",
      "691. feature 421 (0.012844)\n",
      "692. feature 753 (0.012832)\n",
      "693. feature 879 (0.012829)\n",
      "694. feature 65 (0.012815)\n",
      "695. feature 872 (0.012796)\n",
      "696. feature 309 (0.012758)\n",
      "697. feature 389 (0.012729)\n",
      "698. feature 737 (0.012717)\n",
      "699. feature 257 (0.012712)\n",
      "700. feature 391 (0.012689)\n",
      "701. feature 1207 (0.012688)\n",
      "702. feature 364 (0.012648)\n",
      "703. feature 903 (0.012647)\n",
      "704. feature 750 (0.012601)\n",
      "705. feature 491 (0.012579)\n",
      "706. feature 622 (0.012505)\n",
      "707. feature 16 (0.012450)\n",
      "708. feature 161 (0.012410)\n",
      "709. feature 862 (0.012378)\n",
      "710. feature 379 (0.012363)\n",
      "711. feature 727 (0.012360)\n",
      "712. feature 30 (0.012343)\n",
      "713. feature 794 (0.012328)\n",
      "714. feature 248 (0.012263)\n",
      "715. feature 1206 (0.012164)\n",
      "716. feature 707 (0.012128)\n",
      "717. feature 279 (0.012096)\n",
      "718. feature 141 (0.012077)\n",
      "719. feature 766 (0.012076)\n",
      "720. feature 401 (0.012065)\n",
      "721. feature 1210 (0.012064)\n",
      "722. feature 697 (0.012061)\n",
      "723. feature 700 (0.011982)\n",
      "724. feature 276 (0.011959)\n",
      "725. feature 715 (0.011939)\n",
      "726. feature 323 (0.011934)\n",
      "727. feature 406 (0.011920)\n",
      "728. feature 31 (0.011878)\n",
      "729. feature 88 (0.011842)\n",
      "730. feature 253 (0.011828)\n",
      "731. feature 453 (0.011817)\n",
      "732. feature 99 (0.011783)\n",
      "733. feature 107 (0.011749)\n",
      "734. feature 572 (0.011732)\n",
      "735. feature 211 (0.011725)\n",
      "736. feature 0 (0.011689)\n",
      "737. feature 39 (0.011684)\n",
      "738. feature 307 (0.011678)\n",
      "739. feature 558 (0.011658)\n",
      "740. feature 222 (0.011638)\n",
      "741. feature 869 (0.011634)\n",
      "742. feature 605 (0.011632)\n",
      "743. feature 880 (0.011610)\n",
      "744. feature 256 (0.011590)\n",
      "745. feature 564 (0.011580)\n",
      "746. feature 55 (0.011571)\n",
      "747. feature 231 (0.011559)\n",
      "748. feature 871 (0.011545)\n",
      "749. feature 611 (0.011533)\n",
      "750. feature 742 (0.011501)\n",
      "751. feature 456 (0.011501)\n",
      "752. feature 321 (0.011484)\n",
      "753. feature 119 (0.011452)\n",
      "754. feature 708 (0.011410)\n",
      "755. feature 62 (0.011394)\n",
      "756. feature 580 (0.011326)\n",
      "757. feature 870 (0.011299)\n",
      "758. feature 692 (0.011297)\n",
      "759. feature 166 (0.011253)\n",
      "760. feature 1074 (0.011209)\n",
      "761. feature 142 (0.011208)\n",
      "762. feature 762 (0.011205)\n",
      "763. feature 579 (0.011184)\n",
      "764. feature 122 (0.011183)\n",
      "765. feature 290 (0.011182)\n",
      "766. feature 397 (0.011169)\n",
      "767. feature 907 (0.011146)\n",
      "768. feature 35 (0.011127)\n",
      "769. feature 331 (0.011089)\n",
      "770. feature 1158 (0.011030)\n",
      "771. feature 1188 (0.011026)\n",
      "772. feature 1133 (0.010988)\n",
      "773. feature 617 (0.010983)\n",
      "774. feature 402 (0.010981)\n",
      "775. feature 407 (0.010967)\n",
      "776. feature 370 (0.010957)\n",
      "777. feature 844 (0.010956)\n",
      "778. feature 319 (0.010935)\n",
      "779. feature 212 (0.010933)\n",
      "780. feature 770 (0.010932)\n",
      "781. feature 613 (0.010927)\n",
      "782. feature 802 (0.010897)\n",
      "783. feature 900 (0.010892)\n",
      "784. feature 362 (0.010887)\n",
      "785. feature 434 (0.010884)\n",
      "786. feature 128 (0.010845)\n",
      "787. feature 865 (0.010818)\n",
      "788. feature 92 (0.010771)\n",
      "789. feature 823 (0.010697)\n",
      "790. feature 43 (0.010689)\n",
      "791. feature 451 (0.010652)\n",
      "792. feature 44 (0.010634)\n",
      "793. feature 728 (0.010570)\n",
      "794. feature 926 (0.010561)\n",
      "795. feature 713 (0.010555)\n",
      "796. feature 702 (0.010544)\n",
      "797. feature 85 (0.010538)\n",
      "798. feature 258 (0.010529)\n",
      "799. feature 71 (0.010512)\n",
      "800. feature 335 (0.010462)\n",
      "801. feature 120 (0.010442)\n",
      "802. feature 316 (0.010440)\n",
      "803. feature 198 (0.010433)\n",
      "804. feature 82 (0.010379)\n",
      "805. feature 1173 (0.010375)\n",
      "806. feature 97 (0.010365)\n",
      "807. feature 83 (0.010349)\n",
      "808. feature 255 (0.010330)\n",
      "809. feature 172 (0.010298)\n",
      "810. feature 1043 (0.010170)\n",
      "811. feature 1015 (0.010160)\n",
      "812. feature 91 (0.010157)\n",
      "813. feature 997 (0.010149)\n",
      "814. feature 847 (0.010136)\n",
      "815. feature 734 (0.010125)\n",
      "816. feature 145 (0.010105)\n",
      "817. feature 146 (0.010100)\n",
      "818. feature 604 (0.010093)\n",
      "819. feature 77 (0.010068)\n",
      "820. feature 27 (0.010066)\n",
      "821. feature 64 (0.010060)\n",
      "822. feature 70 (0.010018)\n",
      "823. feature 366 (0.010016)\n",
      "824. feature 1008 (0.010010)\n",
      "825. feature 592 (0.009995)\n",
      "826. feature 490 (0.009992)\n",
      "827. feature 774 (0.009986)\n",
      "828. feature 720 (0.009955)\n",
      "829. feature 1161 (0.009933)\n",
      "830. feature 782 (0.009928)\n",
      "831. feature 466 (0.009915)\n",
      "832. feature 360 (0.009886)\n",
      "833. feature 706 (0.009854)\n",
      "834. feature 132 (0.009851)\n",
      "835. feature 936 (0.009843)\n",
      "836. feature 10 (0.009840)\n",
      "837. feature 294 (0.009817)\n",
      "838. feature 722 (0.009802)\n",
      "839. feature 541 (0.009788)\n",
      "840. feature 50 (0.009785)\n",
      "841. feature 51 (0.009755)\n",
      "842. feature 464 (0.009721)\n",
      "843. feature 835 (0.009712)\n",
      "844. feature 465 (0.009700)\n",
      "845. feature 356 (0.009675)\n",
      "846. feature 1129 (0.009660)\n",
      "847. feature 234 (0.009643)\n",
      "848. feature 9 (0.009632)\n",
      "849. feature 238 (0.009624)\n",
      "850. feature 217 (0.009618)\n",
      "851. feature 158 (0.009588)\n",
      "852. feature 181 (0.009556)\n",
      "853. feature 829 (0.009526)\n",
      "854. feature 726 (0.009526)\n",
      "855. feature 104 (0.009526)\n",
      "856. feature 289 (0.009512)\n",
      "857. feature 153 (0.009506)\n",
      "858. feature 565 (0.009490)\n",
      "859. feature 1 (0.009480)\n",
      "860. feature 993 (0.009453)\n",
      "861. feature 261 (0.009448)\n",
      "862. feature 489 (0.009433)\n",
      "863. feature 17 (0.009427)\n",
      "864. feature 301 (0.009426)\n",
      "865. feature 1098 (0.009424)\n",
      "866. feature 278 (0.009413)\n",
      "867. feature 933 (0.009406)\n",
      "868. feature 854 (0.009402)\n",
      "869. feature 888 (0.009390)\n",
      "870. feature 559 (0.009383)\n",
      "871. feature 115 (0.009373)\n",
      "872. feature 1055 (0.009358)\n",
      "873. feature 308 (0.009342)\n",
      "874. feature 84 (0.009306)\n",
      "875. feature 156 (0.009288)\n",
      "876. feature 537 (0.009282)\n",
      "877. feature 286 (0.009278)\n",
      "878. feature 704 (0.009264)\n",
      "879. feature 915 (0.009263)\n",
      "880. feature 263 (0.009247)\n",
      "881. feature 118 (0.009171)\n",
      "882. feature 245 (0.009096)\n",
      "883. feature 67 (0.009091)\n",
      "884. feature 896 (0.009082)\n",
      "885. feature 522 (0.009037)\n",
      "886. feature 127 (0.009036)\n",
      "887. feature 47 (0.009016)\n",
      "888. feature 845 (0.009006)\n",
      "889. feature 165 (0.008985)\n",
      "890. feature 885 (0.008962)\n",
      "891. feature 772 (0.008962)\n",
      "892. feature 170 (0.008953)\n",
      "893. feature 1209 (0.008949)\n",
      "894. feature 314 (0.008948)\n",
      "895. feature 28 (0.008935)\n",
      "896. feature 405 (0.008896)\n",
      "897. feature 191 (0.008894)\n",
      "898. feature 126 (0.008881)\n",
      "899. feature 80 (0.008836)\n",
      "900. feature 60 (0.008828)\n",
      "901. feature 891 (0.008792)\n",
      "902. feature 281 (0.008756)\n",
      "903. feature 623 (0.008739)\n",
      "904. feature 859 (0.008718)\n",
      "905. feature 317 (0.008717)\n",
      "906. feature 510 (0.008714)\n",
      "907. feature 686 (0.008687)\n",
      "908. feature 242 (0.008652)\n",
      "909. feature 755 (0.008644)\n",
      "910. feature 291 (0.008643)\n",
      "911. feature 52 (0.008642)\n",
      "912. feature 139 (0.008629)\n",
      "913. feature 208 (0.008616)\n",
      "914. feature 939 (0.008612)\n",
      "915. feature 303 (0.008558)\n",
      "916. feature 148 (0.008545)\n",
      "917. feature 867 (0.008543)\n",
      "918. feature 740 (0.008514)\n",
      "919. feature 1058 (0.008514)\n",
      "920. feature 1068 (0.008510)\n",
      "921. feature 832 (0.008509)\n",
      "922. feature 754 (0.008441)\n",
      "923. feature 1180 (0.008409)\n",
      "924. feature 299 (0.008370)\n",
      "925. feature 861 (0.008356)\n",
      "926. feature 743 (0.008352)\n",
      "927. feature 93 (0.008347)\n",
      "928. feature 187 (0.008343)\n",
      "929. feature 113 (0.008332)\n",
      "930. feature 277 (0.008315)\n",
      "931. feature 280 (0.008294)\n",
      "932. feature 69 (0.008275)\n",
      "933. feature 460 (0.008272)\n",
      "934. feature 1185 (0.008271)\n",
      "935. feature 1183 (0.008267)\n",
      "936. feature 372 (0.008266)\n",
      "937. feature 375 (0.008237)\n",
      "938. feature 916 (0.008236)\n",
      "939. feature 925 (0.008228)\n",
      "940. feature 920 (0.008227)\n",
      "941. feature 694 (0.008203)\n",
      "942. feature 440 (0.008198)\n",
      "943. feature 448 (0.008175)\n",
      "944. feature 188 (0.008143)\n",
      "945. feature 293 (0.008129)\n",
      "946. feature 298 (0.008096)\n",
      "947. feature 367 (0.008095)\n",
      "948. feature 409 (0.008090)\n",
      "949. feature 1056 (0.008084)\n",
      "950. feature 1079 (0.008078)\n",
      "951. feature 1063 (0.008057)\n",
      "952. feature 533 (0.008054)\n",
      "953. feature 159 (0.008038)\n",
      "954. feature 232 (0.008028)\n",
      "955. feature 773 (0.007999)\n",
      "956. feature 241 (0.007976)\n",
      "957. feature 112 (0.007959)\n",
      "958. feature 105 (0.007955)\n",
      "959. feature 374 (0.007930)\n",
      "960. feature 459 (0.007883)\n",
      "961. feature 78 (0.007872)\n",
      "962. feature 304 (0.007849)\n",
      "963. feature 363 (0.007848)\n",
      "964. feature 94 (0.007839)\n",
      "965. feature 1157 (0.007803)\n",
      "966. feature 40 (0.007798)\n",
      "967. feature 259 (0.007765)\n",
      "968. feature 86 (0.007748)\n",
      "969. feature 155 (0.007747)\n",
      "970. feature 154 (0.007741)\n",
      "971. feature 330 (0.007688)\n",
      "972. feature 302 (0.007676)\n",
      "973. feature 171 (0.007657)\n",
      "974. feature 33 (0.007616)\n",
      "975. feature 1175 (0.007613)\n",
      "976. feature 365 (0.007589)\n",
      "977. feature 15 (0.007575)\n",
      "978. feature 167 (0.007559)\n",
      "979. feature 297 (0.007544)\n",
      "980. feature 1113 (0.007532)\n",
      "981. feature 691 (0.007478)\n",
      "982. feature 1192 (0.007432)\n",
      "983. feature 884 (0.007422)\n",
      "984. feature 479 (0.007410)\n",
      "985. feature 1054 (0.007395)\n",
      "986. feature 285 (0.007379)\n",
      "987. feature 701 (0.007357)\n",
      "988. feature 679 (0.007352)\n",
      "989. feature 322 (0.007332)\n",
      "990. feature 725 (0.007310)\n",
      "991. feature 125 (0.007305)\n",
      "992. feature 282 (0.007303)\n",
      "993. feature 1132 (0.007251)\n",
      "994. feature 758 (0.007226)\n",
      "995. feature 761 (0.007216)\n",
      "996. feature 763 (0.007211)\n",
      "997. feature 529 (0.007175)\n",
      "998. feature 228 (0.007168)\n",
      "999. feature 906 (0.007168)\n",
      "1000. feature 530 (0.007158)\n",
      "1001. feature 918 (0.007155)\n",
      "1002. feature 1049 (0.007155)\n",
      "1003. feature 744 (0.007144)\n",
      "1004. feature 721 (0.007143)\n",
      "1005. feature 350 (0.007132)\n",
      "1006. feature 500 (0.007113)\n",
      "1007. feature 919 (0.007083)\n",
      "1008. feature 110 (0.007065)\n",
      "1009. feature 327 (0.007057)\n",
      "1010. feature 334 (0.007020)\n",
      "1011. feature 930 (0.007019)\n",
      "1012. feature 223 (0.007019)\n",
      "1013. feature 454 (0.006980)\n",
      "1014. feature 771 (0.006953)\n",
      "1015. feature 108 (0.006945)\n",
      "1016. feature 287 (0.006907)\n",
      "1017. feature 1156 (0.006876)\n",
      "1018. feature 751 (0.006873)\n",
      "1019. feature 515 (0.006869)\n",
      "1020. feature 1154 (0.006830)\n",
      "1021. feature 1104 (0.006805)\n",
      "1022. feature 1004 (0.006795)\n",
      "1023. feature 560 (0.006777)\n",
      "1024. feature 689 (0.006746)\n",
      "1025. feature 79 (0.006738)\n",
      "1026. feature 732 (0.006733)\n",
      "1027. feature 111 (0.006705)\n",
      "1028. feature 683 (0.006675)\n",
      "1029. feature 1208 (0.006657)\n",
      "1030. feature 204 (0.006638)\n",
      "1031. feature 769 (0.006636)\n",
      "1032. feature 878 (0.006602)\n",
      "1033. feature 320 (0.006564)\n",
      "1034. feature 902 (0.006543)\n",
      "1035. feature 54 (0.006510)\n",
      "1036. feature 48 (0.006504)\n",
      "1037. feature 439 (0.006480)\n",
      "1038. feature 135 (0.006454)\n",
      "1039. feature 856 (0.006451)\n",
      "1040. feature 741 (0.006440)\n",
      "1041. feature 886 (0.006425)\n",
      "1042. feature 147 (0.006423)\n",
      "1043. feature 952 (0.006406)\n",
      "1044. feature 890 (0.006395)\n",
      "1045. feature 507 (0.006390)\n",
      "1046. feature 1111 (0.006380)\n",
      "1047. feature 1022 (0.006352)\n",
      "1048. feature 1134 (0.006334)\n",
      "1049. feature 121 (0.006331)\n",
      "1050. feature 144 (0.006327)\n",
      "1051. feature 682 (0.006308)\n",
      "1052. feature 136 (0.006307)\n",
      "1053. feature 284 (0.006265)\n",
      "1054. feature 516 (0.006239)\n",
      "1055. feature 457 (0.006225)\n",
      "1056. feature 501 (0.006194)\n",
      "1057. feature 718 (0.006192)\n",
      "1058. feature 149 (0.006175)\n",
      "1059. feature 68 (0.006144)\n",
      "1060. feature 472 (0.006082)\n",
      "1061. feature 676 (0.006073)\n",
      "1062. feature 733 (0.006047)\n",
      "1063. feature 858 (0.006014)\n",
      "1064. feature 150 (0.006008)\n",
      "1065. feature 168 (0.006000)\n",
      "1066. feature 95 (0.005993)\n",
      "1067. feature 143 (0.005985)\n",
      "1068. feature 527 (0.005944)\n",
      "1069. feature 932 (0.005901)\n",
      "1070. feature 114 (0.005870)\n",
      "1071. feature 292 (0.005862)\n",
      "1072. feature 1060 (0.005850)\n",
      "1073. feature 251 (0.005821)\n",
      "1074. feature 1099 (0.005807)\n",
      "1075. feature 898 (0.005776)\n",
      "1076. feature 89 (0.005763)\n",
      "1077. feature 173 (0.005733)\n",
      "1078. feature 134 (0.005720)\n",
      "1079. feature 1106 (0.005714)\n",
      "1080. feature 719 (0.005692)\n",
      "1081. feature 922 (0.005654)\n",
      "1082. feature 910 (0.005626)\n",
      "1083. feature 247 (0.005607)\n",
      "1084. feature 1143 (0.005606)\n",
      "1085. feature 452 (0.005605)\n",
      "1086. feature 133 (0.005573)\n",
      "1087. feature 502 (0.005520)\n",
      "1088. feature 1085 (0.005514)\n",
      "1089. feature 767 (0.005505)\n",
      "1090. feature 731 (0.005493)\n",
      "1091. feature 901 (0.005477)\n",
      "1092. feature 928 (0.005467)\n",
      "1093. feature 863 (0.005455)\n",
      "1094. feature 584 (0.005444)\n",
      "1095. feature 924 (0.005438)\n",
      "1096. feature 511 (0.005432)\n",
      "1097. feature 1084 (0.005425)\n",
      "1098. feature 151 (0.005407)\n",
      "1099. feature 477 (0.005401)\n",
      "1100. feature 1083 (0.005366)\n",
      "1101. feature 458 (0.005320)\n",
      "1102. feature 893 (0.005319)\n",
      "1103. feature 305 (0.005308)\n",
      "1104. feature 850 (0.005293)\n",
      "1105. feature 1059 (0.005284)\n",
      "1106. feature 182 (0.005275)\n",
      "1107. feature 1155 (0.005261)\n",
      "1108. feature 73 (0.005227)\n",
      "1109. feature 1081 (0.005176)\n",
      "1110. feature 486 (0.005162)\n",
      "1111. feature 923 (0.005155)\n",
      "1112. feature 895 (0.005151)\n",
      "1113. feature 557 (0.005122)\n",
      "1114. feature 1057 (0.005115)\n",
      "1115. feature 887 (0.005110)\n",
      "1116. feature 757 (0.005109)\n",
      "1117. feature 306 (0.005075)\n",
      "1118. feature 748 (0.005070)\n",
      "1119. feature 764 (0.005040)\n",
      "1120. feature 1108 (0.004953)\n",
      "1121. feature 138 (0.004944)\n",
      "1122. feature 562 (0.004937)\n",
      "1123. feature 724 (0.004909)\n",
      "1124. feature 1186 (0.004874)\n",
      "1125. feature 532 (0.004845)\n",
      "1126. feature 1181 (0.004834)\n",
      "1127. feature 483 (0.004823)\n",
      "1128. feature 481 (0.004803)\n",
      "1129. feature 130 (0.004789)\n",
      "1130. feature 1135 (0.004783)\n",
      "1131. feature 152 (0.004765)\n",
      "1132. feature 441 (0.004745)\n",
      "1133. feature 717 (0.004706)\n",
      "1134. feature 328 (0.004692)\n",
      "1135. feature 46 (0.004656)\n",
      "1136. feature 716 (0.004651)\n",
      "1137. feature 1160 (0.004650)\n",
      "1138. feature 904 (0.004617)\n",
      "1139. feature 913 (0.004598)\n",
      "1140. feature 577 (0.004597)\n",
      "1141. feature 433 (0.004517)\n",
      "1142. feature 461 (0.004489)\n",
      "1143. feature 295 (0.004486)\n",
      "1144. feature 1062 (0.004471)\n",
      "1145. feature 1107 (0.004392)\n",
      "1146. feature 868 (0.004349)\n",
      "1147. feature 735 (0.004294)\n",
      "1148. feature 883 (0.004282)\n",
      "1149. feature 163 (0.004282)\n",
      "1150. feature 485 (0.004264)\n",
      "1151. feature 892 (0.004224)\n",
      "1152. feature 1061 (0.004214)\n",
      "1153. feature 927 (0.004193)\n",
      "1154. feature 882 (0.004184)\n",
      "1155. feature 1159 (0.004165)\n",
      "1156. feature 889 (0.004114)\n",
      "1157. feature 455 (0.004107)\n",
      "1158. feature 311 (0.004105)\n",
      "1159. feature 123 (0.004057)\n",
      "1160. feature 1086 (0.004030)\n",
      "1161. feature 1082 (0.003943)\n",
      "1162. feature 1179 (0.003936)\n",
      "1163. feature 528 (0.003923)\n",
      "1164. feature 361 (0.003919)\n",
      "1165. feature 765 (0.003903)\n",
      "1166. feature 929 (0.003893)\n",
      "1167. feature 1109 (0.003836)\n",
      "1168. feature 738 (0.003825)\n",
      "1169. feature 124 (0.003775)\n",
      "1170. feature 583 (0.003772)\n",
      "1171. feature 131 (0.003772)\n",
      "1172. feature 369 (0.003737)\n",
      "1173. feature 552 (0.003716)\n",
      "1174. feature 554 (0.003667)\n",
      "1175. feature 313 (0.003621)\n",
      "1176. feature 1080 (0.003533)\n",
      "1177. feature 736 (0.003524)\n",
      "1178. feature 482 (0.003494)\n",
      "1179. feature 1105 (0.003485)\n",
      "1180. feature 244 (0.003429)\n",
      "1181. feature 921 (0.003396)\n",
      "1182. feature 1182 (0.003375)\n",
      "1183. feature 478 (0.003340)\n",
      "1184. feature 1088 (0.003275)\n",
      "1185. feature 905 (0.003200)\n",
      "1186. feature 300 (0.003197)\n",
      "1187. feature 505 (0.003166)\n",
      "1188. feature 508 (0.003138)\n",
      "1189. feature 312 (0.003068)\n",
      "1190. feature 169 (0.002997)\n",
      "1191. feature 140 (0.002984)\n",
      "1192. feature 578 (0.002982)\n",
      "1193. feature 1130 (0.002915)\n",
      "1194. feature 480 (0.002906)\n",
      "1195. feature 1112 (0.002817)\n",
      "1196. feature 739 (0.002793)\n",
      "1197. feature 117 (0.002736)\n",
      "1198. feature 503 (0.002720)\n",
      "1199. feature 310 (0.002704)\n",
      "1200. feature 288 (0.002690)\n",
      "1201. feature 553 (0.002623)\n",
      "1202. feature 864 (0.002589)\n",
      "1203. feature 1184 (0.002561)\n",
      "1204. feature 315 (0.002540)\n",
      "1205. feature 129 (0.002398)\n",
      "1206. feature 509 (0.002393)\n",
      "1207. feature 1110 (0.002296)\n",
      "1208. feature 506 (0.002003)\n",
      "1209. feature 582 (0.001851)\n",
      "1210. feature 1131 (0.001783)\n",
      "1211. feature 504 (0.001686)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEIO+JDWIQV+SGuT/A1X8A8LEITD1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb694e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize feature importances\n",
    "\n",
    "importances = np.array(importances)\n",
    "importances /= importances.max()\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number of features: 123\n",
      "1. feature 388 (1.000000)\n",
      "2. feature 988 (0.977711)\n",
      "3. feature 990 (0.900733)\n",
      "4. feature 956 (0.771606)\n",
      "5. feature 386 (0.742600)\n",
      "6. feature 989 (0.738875)\n",
      "7. feature 1045 (0.698334)\n",
      "8. feature 1071 (0.671445)\n",
      "9. feature 1121 (0.647973)\n",
      "10. feature 387 (0.642872)\n",
      "11. feature 609 (0.535209)\n",
      "12. feature 1011 (0.515246)\n",
      "13. feature 1120 (0.470980)\n",
      "14. feature 965 (0.455276)\n",
      "15. feature 966 (0.441449)\n",
      "16. feature 183 (0.439641)\n",
      "17. feature 1144 (0.436431)\n",
      "18. feature 1146 (0.431465)\n",
      "19. feature 1010 (0.392307)\n",
      "20. feature 955 (0.376049)\n",
      "21. feature 1171 (0.367005)\n",
      "22. feature 1046 (0.363573)\n",
      "23. feature 1119 (0.348404)\n",
      "24. feature 1070 (0.326618)\n",
      "25. feature 985 (0.326367)\n",
      "26. feature 787 (0.325820)\n",
      "27. feature 184 (0.322909)\n",
      "28. feature 1190 (0.315951)\n",
      "29. feature 946 (0.313070)\n",
      "30. feature 945 (0.311466)\n",
      "31. feature 625 (0.288289)\n",
      "32. feature 599 (0.283205)\n",
      "33. feature 1203 (0.275502)\n",
      "34. feature 786 (0.274288)\n",
      "35. feature 1145 (0.269851)\n",
      "36. feature 627 (0.259795)\n",
      "37. feature 1196 (0.229907)\n",
      "38. feature 971 (0.229471)\n",
      "39. feature 1191 (0.229204)\n",
      "40. feature 1201 (0.223834)\n",
      "41. feature 964 (0.222412)\n",
      "42. feature 957 (0.214817)\n",
      "43. feature 1095 (0.213715)\n",
      "44. feature 944 (0.213422)\n",
      "45. feature 785 (0.209098)\n",
      "46. feature 1009 (0.208125)\n",
      "47. feature 492 (0.204614)\n",
      "48. feature 970 (0.204508)\n",
      "49. feature 1169 (0.204058)\n",
      "50. feature 1193 (0.195755)\n",
      "51. feature 343 (0.195566)\n",
      "52. feature 789 (0.193906)\n",
      "53. feature 517 (0.193640)\n",
      "54. feature 1031 (0.191329)\n",
      "55. feature 569 (0.189956)\n",
      "56. feature 940 (0.186949)\n",
      "57. feature 1170 (0.186620)\n",
      "58. feature 996 (0.186054)\n",
      "59. feature 1094 (0.183038)\n",
      "60. feature 573 (0.180327)\n",
      "61. feature 1012 (0.176257)\n",
      "62. feature 519 (0.176134)\n",
      "63. feature 1018 (0.175681)\n",
      "64. feature 979 (0.173901)\n",
      "65. feature 986 (0.171150)\n",
      "66. feature 601 (0.166847)\n",
      "67. feature 987 (0.166271)\n",
      "68. feature 494 (0.165480)\n",
      "69. feature 608 (0.160871)\n",
      "70. feature 1122 (0.158661)\n",
      "71. feature 1030 (0.157936)\n",
      "72. feature 1044 (0.157057)\n",
      "73. feature 943 (0.154316)\n",
      "74. feature 779 (0.153462)\n",
      "75. feature 972 (0.153183)\n",
      "76. feature 1047 (0.152121)\n",
      "77. feature 1069 (0.150178)\n",
      "78. feature 610 (0.148009)\n",
      "79. feature 1032 (0.146918)\n",
      "80. feature 442 (0.143706)\n",
      "81. feature 954 (0.143051)\n",
      "82. feature 589 (0.141904)\n",
      "83. feature 941 (0.140116)\n",
      "84. feature 185 (0.138772)\n",
      "85. feature 341 (0.137605)\n",
      "86. feature 967 (0.136976)\n",
      "87. feature 549 (0.136712)\n",
      "88. feature 968 (0.136273)\n",
      "89. feature 949 (0.130187)\n",
      "90. feature 636 (0.128719)\n",
      "91. feature 383 (0.126016)\n",
      "92. feature 1001 (0.125854)\n",
      "93. feature 1097 (0.124800)\n",
      "94. feature 654 (0.123483)\n",
      "95. feature 574 (0.122993)\n",
      "96. feature 788 (0.122915)\n",
      "97. feature 524 (0.122337)\n",
      "98. feature 1096 (0.121534)\n",
      "99. feature 568 (0.121384)\n",
      "100. feature 1072 (0.120767)\n",
      "101. feature 526 (0.119476)\n",
      "102. feature 1014 (0.117743)\n",
      "103. feature 1147 (0.116443)\n",
      "104. feature 1000 (0.115442)\n",
      "105. feature 1200 (0.115169)\n",
      "106. feature 444 (0.113497)\n",
      "107. feature 591 (0.113129)\n",
      "108. feature 468 (0.112973)\n",
      "109. feature 543 (0.112503)\n",
      "110. feature 626 (0.112281)\n",
      "111. feature 994 (0.109538)\n",
      "112. feature 1013 (0.108876)\n",
      "113. feature 338 (0.108284)\n",
      "114. feature 1026 (0.107779)\n",
      "115. feature 23 (0.107451)\n",
      "116. feature 571 (0.107090)\n",
      "117. feature 1035 (0.105871)\n",
      "118. feature 544 (0.105101)\n",
      "119. feature 1195 (0.104798)\n",
      "120. feature 1204 (0.103536)\n",
      "121. feature 422 (0.103063)\n",
      "122. feature 1065 (0.103060)\n",
      "123. feature 520 (0.101049)\n"
     ]
    }
   ],
   "source": [
    "# select features > 10 % importance\n",
    "features = [i for i,j in zip(features,importances) if j > 0.1]\n",
    "\n",
    "print (\"Selected number of features: %d\" % len(features))\n",
    "\n",
    "for f in range(len(features)):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishparii\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\ishparii\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn import metrics, svm, neighbors, linear_model, tree\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting data for training\n",
    "X = data_train[features] # data for training\n",
    "Y = data_train['label'] # target labels\n",
    "groups = data_train['subj_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines : \n",
      "Best score for  Support Vector Machines : 0.9584424083769634\n",
      "\n",
      "Best parameters for  Support Vector Machines  found on development set: {'C': 10000000.0}\n",
      "\n",
      "Best estimator for  Support Vector Machines  model: LinearSVC(C=10000000.0, class_weight='balanced', dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      "     tol=0.0001, verbose=0)\n",
      "\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.903 (+/-0.144) for {'C': 1e-06}\n",
      "0.797 (+/-0.614) for {'C': 1e-05}\n",
      "0.913 (+/-0.202) for {'C': 0.0001}\n",
      "0.890 (+/-0.359) for {'C': 0.001}\n",
      "0.918 (+/-0.236) for {'C': 0.01}\n",
      "0.895 (+/-0.399) for {'C': 0.1}\n",
      "0.901 (+/-0.173) for {'C': 1}\n",
      "0.924 (+/-0.150) for {'C': 10.0}\n",
      "0.906 (+/-0.269) for {'C': 100.0}\n",
      "0.928 (+/-0.112) for {'C': 1000.0}\n",
      "0.881 (+/-0.194) for {'C': 10000.0}\n",
      "0.888 (+/-0.241) for {'C': 100000.0}\n",
      "0.930 (+/-0.117) for {'C': 1000000.0}\n",
      "0.958 (+/-0.034) for {'C': 10000000.0}\n",
      "0.890 (+/-0.377) for {'C': 100000000.0}\n",
      "0.881 (+/-0.450) for {'C': 1000000000.0}\n",
      "0.878 (+/-0.386) for {'C': 10000000000.0}\n",
      "0.911 (+/-0.128) for {'C': 100000000000.0}\n",
      "0.866 (+/-0.469) for {'C': 1000000000000.0}\n",
      "0.832 (+/-0.471) for {'C': 10000000000000.0}\n",
      "0.924 (+/-0.147) for {'C': 100000000000000.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Different models to try\n",
    "#       Model name ---------------------------------------------------------------------\n",
    "#      Parameters ------------------------------------------                           |\n",
    "#     Classifier -----------                               |                           |\n",
    "#                          |                               |                           |\n",
    "#                          v                               v                           |\n",
    "models = [#[tree.DecisionTreeClassifier(), {'min_samples_split': [2, 4, 6, 8, 10],#    |\n",
    "#                                           'min_samples_leaf': [1, 5, 10, 15, 20],#     v\n",
    "#                                           'max_depth': [1, 10, 20, 30, 40, 50]},       \"Decision Tree\"]\n",
    "          ]\n",
    "\n",
    "# models.append([linear_model.LogisticRegression(), {'C': [1e-3, 1e-2, 1e-1, 1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5, 1e+6, 1e+7, 1e+8, 1e+9, 1e+10]}, \"Logistic Regression with Ridge Penalty\"])\n",
    "\n",
    "# models.append([linear_model.LogisticRegression(penalty='l1'), {'C': [0.001, 0.01, 0.1, 1, 10, 100]}, \"Logistic Regression with Lasso Penalty\"])\n",
    "\n",
    "models.append([svm.LinearSVC(class_weight='balanced'), {\n",
    "#                            'gamma': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5, 1e+6], \n",
    "                           'C': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5, 1e+6, 1e+7, 1e+8, 1e+9, 1e+10, 1e+11, 1e+12, 1e+13, 1e+14]}, \"Support Vector Machines\"])\n",
    "\n",
    "# models.append([neighbors.KNeighborsClassifier(), {'n_neighbors': [1, 3, 5, 7, 10]}, \"K-Nearest Neighbors\"])\n",
    "\n",
    "\n",
    "\n",
    "# models.append([ RandomForestClassifier(), {'n_estimators': [1, 10, 20, 30, 40, 50],\n",
    "#                                           'max_depth': [1, 10, 20, 30, 40, 50],\n",
    "#                                           'min_samples_leaf': [1, 5, 10, 15, 20],\n",
    "#                                           'min_samples_split': [2, 4, 6, 8, 10]\n",
    "#                                           }, \"Random Forest\"])\n",
    "\n",
    "models_with_best_params = []\n",
    "\n",
    "# cross-validation strategy\n",
    "# cv = 10 # for 10-folds cross-validation\n",
    "\n",
    "# Leave One Group Out\n",
    "logo = LeaveOneGroupOut()\n",
    "cv = logo.get_n_splits(X,Y,groups)\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    clf = GridSearchCV(model[0], model[1], cv=cv)\n",
    "    clf.fit(X, Y)\n",
    "    best_params = clf.best_params_\n",
    "    best_estimator = clf.best_estimator_\n",
    "    \n",
    "    model_with_best_params = [best_estimator, best_params, model[2]]\n",
    "    \n",
    "    models_with_best_params.append(model_with_best_params)\n",
    "    \n",
    "    print(model[2], \": \")\n",
    "    print(\"Best score for \", model[2], \":\", clf.best_score_)\n",
    "    print()\n",
    "    print(\"Best parameters for \", model[2], \" found on development set:\", best_params)\n",
    "    print()\n",
    "    print(\"Best estimator for \", model[2], \" model:\", best_estimator)\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in clf.grid_scores_: \n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "\n",
    "# print(models_with_best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy for Support Vector Machines model is 0.947503201024\n",
      "Classification report for classifier LinearSVC(C=10000000.0, class_weight='balanced', dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=None,\n",
      "     tol=0.0001, verbose=0):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0    0.99376   0.94510   0.96882       674\n",
      "        9.0    0.73571   0.96262   0.83401       107\n",
      "\n",
      "avg / total    0.95841   0.94750   0.95035       781\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[637  37]\n",
      " [  4 103]]\n"
     ]
    }
   ],
   "source": [
    "#fitting models to test_data\n",
    "for model in models_with_best_params:\n",
    "    classifier = model[0]\n",
    "    classifier.fit(X, Y)\n",
    "    score = classifier.score(data_test[features], data_test['label'])\n",
    "    print(\"Prediction accuracy for\", model[2], \"model is\", score)\n",
    "    expected = data_test['label']\n",
    "    predicted = classifier.predict(data_test[features])\n",
    "\n",
    "    print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted, digits=5)))\n",
    "    print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
